[
  {
    "objectID": "topics/discrete_predictor/index.html",
    "href": "topics/discrete_predictor/index.html",
    "title": "Palmer penguins and discrete predictors",
    "section": "",
    "text": "Let’s start by taking a look at the Palmer Penguin dataset. Let’s look at the distribution of observations of bill size.\nThere’s quite a lot of variation in these measurements, with a suggestion of perhaps more than one peak in this distribution."
  },
  {
    "objectID": "topics/discrete_predictor/index.html#a-simple-model",
    "href": "topics/discrete_predictor/index.html#a-simple-model",
    "title": "Palmer penguins and discrete predictors",
    "section": "A simple model",
    "text": "A simple model\n\\[\n\\begin{align}\n\\text{Bill depth} &\\sim \\text{Normal}(\\mu, \\sigma)\\\\\n\\mu &\\sim \\text{Normal}(17.5, 2) \\\\\n\\sigma &\\sim \\text{Exponential}(1) \\\\\n\\end{align}\n\\]\nlet’s express the same model in Stan:\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /Users/amacdonald/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\nnormal_dist <- cmdstan_model(\"topics/discrete_predictor/normal_dist.stan\")\nnormal_dist\n\ndata {\n  int N;\n  vector[N] measurements;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  measurements ~ normal(mu, sigma);\n  mu ~ normal(17,2);\n  sigma ~ exponential(1);\n}\n\n\nThe model section looks very much like the approach shown above. I want you to notice especially how the bottom chunk has three lines, each describing a probability distribution. These are for all the probability distribution of all the quantities in the model, both observed and unobserved. Above, we state which is which. Models are devices for putting together the probability of all the quantities we are looking for. Again, a Bayesian defines the world as umeasured or measured quantities – and above we state which are observed (the data block) and which are unobserved (the parameters block).\nWe can fit this model to data and see the result:\n\n# first we drop all NA values\npenguins_nobillNA <- penguins |> \n  #drop NA values\n  filter(!is.na(bill_depth_mm))\n\n## then we assemble the data as a list.\n## I'm using the base function with()\n##  it lets me use the variable name directly \n## without writing penguins_nobillNA$bill_depth_mm\n\nlist_bill_dep <- with(penguins_nobillNA,\n     list(N = length(bill_depth_mm),\n          measurements = bill_depth_mm))\n     \n## sample 4 chains, suppress counting iterations\nsamp_bill_dep <- normal_dist$sample(data = list_bill_dep, \n                                    parallel_chains = 4,\n                                    refresh = 0)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.4 seconds.\n\n## summarize the samples for each parameter into a nice table\nsamp_bill_dep |> \n  posterior::summarise_draws() |> \n  flextable::flextable()\n\n\nvariablemeanmediansdmadq5q95rhatess_bulkess_taillp__-405.509997-405.21051.002513050.72128490-407.484200-404.5609501.0001091,895.0662,399.350mu17.15181417.15270.106752740.1046715616.98179017.3298251.0005053,264.9102,629.723sigma1.9762131.97460.075046040.074737871.8555922.1037961.0013022,863.8872,648.369"
  },
  {
    "objectID": "topics/discrete_predictor/index.html#plotting-parameters.",
    "href": "topics/discrete_predictor/index.html#plotting-parameters.",
    "title": "Palmer penguins and discrete predictors",
    "section": "Plotting parameters.",
    "text": "Plotting parameters.\nWe don’t have one distribution for each of our unknown numbers: we have thousands. We need to get a sense of what these possible values mean scientifically. An excellent way to do this is by making as many pictures as possible. We will start with making plots of specific parameters.\nWe can look at the distributions easily using the bayesplot package.\n\ndraws <- samp_bill_dep$draws(variables = c(\"mu\", \"sigma\"))\n\nbayesplot::mcmc_hist(draws, pars = \"mu\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nbayesplot::mcmc_hist(draws, pars = \"sigma\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that the distributions do not have the same shape as the prior– this is particularly true for \\(\\sigma\\). This shows an important point: the prior distribution does not determine what the posterior looks like. should I sample from the prior and show them that?\n\nlibrary(ggplot2)\nlibrary(ggdist)\n\ndraws |>  \n  posterior::as_draws_df() |> \n  ggplot(aes(x = sigma)) + \n  stat_dotsinterval()\n\nWarning: Using the `size` aesthetic with geom_segment was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\nFigure 1: the package ggdist has many fun & useful ways to draw pictures of posterior distributions. Here is one called stats_dotsinterval()"
  },
  {
    "objectID": "topics/discrete_predictor/index.html#posterior-predictions-the-easy-way-to-check-your-model",
    "href": "topics/discrete_predictor/index.html#posterior-predictions-the-easy-way-to-check-your-model",
    "title": "Palmer penguins and discrete predictors",
    "section": "Posterior predictions: the easy way to check your model",
    "text": "Posterior predictions: the easy way to check your model\nPeople care so much about model diagnostics. And with good reason: you need to know how much to trust a model before using it to make a scientific claim. One way to find out who’s model is best would be to use them to make a prediction, and see how right you are. Nobody has the time for that. so instead the best choice is to see how well the data fit your sample.\n\n# just get some draws\ndraws <- samp_bill_dep$draws(variables = c(\"mu\", \"sigma\"))\ndraws_matrix <- posterior::as_draws_matrix(draws)\n\n## set up a matrix. for every posterior sample, \n## (that is, for a value of mu and a value of sigma) \n## draw a whole fake dataset from a normal distribution with that mean and sd. \nnsamples <- 50\nyrep <- matrix(0, ncol = list_bill_dep$N, nrow = nsamples)\n\n# pick some random rows\nset.seed(1234)\nchosen_samples <- sample(1:nrow(draws_matrix), replace = FALSE, size = nsamples)\nsubset_draws <- draws_matrix[chosen_samples,]\n\nfor (r in 1:nsamples){\n yrep[r,] <- rnorm(n = list_bill_dep$N, \n                   mean = subset_draws[r, \"mu\"], \n                   sd = subset_draws[r, \"sigma\"])\n}\n\nbayesplot::ppc_dens_overlay(y = list_bill_dep$measurements,\n                            yrep = yrep)\n\n\n\n\n\nPosterior predictions in Stan\nWe can simulate our own data in R if we are comfortable translating between R and Stan. However, if you want, you can do the same process in Stan. Just combine the section we just looked at with the previous work on data simulation we started with:\n\nnormal_dist_rng <- cmdstan_model(stan_file = \"topics/discrete_predictor/normal_dist_rng.stan\")\n\nnormal_dist_rng\n\ndata {\n  int N;\n  vector[N] measurements;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  measurements ~ normal(mu, sigma);\n  mu ~ normal(17,2);\n  sigma ~ exponential(1);\n}\ngenerated quantities{\n  vector[N] yrep;\n  for (i in 1:N){\n    yrep[i] = normal_rng(mu, sigma);\n  }\n}\n\n\nHere we have a handy random number generator inside Stan.\n\nsamp_bill_dep_rng <- normal_dist_rng$sample(\n  data = list_bill_dep,\n  refresh = 0,\n  parallel_chains = 4)\n\nRunning MCMC with 4 parallel chains...\n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/var/folders/x7/l08zn2396g797m5ws54np_6w0000gp/T/RtmpjkCX3Q/model-2b064a36d475.stan', line 10, column 2 to column 35)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 1 finished in 0.7 seconds.\nChain 2 finished in 0.7 seconds.\nChain 3 finished in 0.8 seconds.\nChain 4 finished in 0.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 1.0 seconds.\n\ndraws <- samp_bill_dep_rng$draws(variables = c(\"yrep\"))\ndraws_matrix <- posterior::as_draws_matrix(draws)\n\nbayesplot::ppc_dens_overlay(y = list_bill_dep$measurements,\n                            yrep = head(draws_matrix, 50))\n\n\n\n\nThe code is much shorter, because there is less to do in R. Both of these gives the same outcome: the posterior predictive distribution. This gives us a straightfoward way to test our model’s performance:\n\nwe use the model to generate fake observations.\nplot these on top of the real data\nif the data is a really poor match, we know our model has a distorted view of the world."
  },
  {
    "objectID": "topics/discrete_predictor/index.html#different-groups-are-different",
    "href": "topics/discrete_predictor/index.html#different-groups-are-different",
    "title": "Palmer penguins and discrete predictors",
    "section": "Different groups are different",
    "text": "Different groups are different\nlet’s add in differences among species\n\npenguins |> \n  ggplot(aes(x = bill_depth_mm, fill = species))+ \n  geom_histogram(binwidth = .5) + \n  scale_fill_brewer(palette = \"Dark2\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nNow we can see that the distribution is in fact three different shapes, all placed together.\n\n\n\n\n\n\nWarning\n\n\n\nSometimes scientists will plot histograms of data at the beginning of a research project, and use the histogram to decide if their data are “normally distributed” or not. This is not helpful! Instead, decide on a model first, and ask yourself what kind of data you expect."
  },
  {
    "objectID": "topics/discrete_predictor/index.html#stan-code-for-species-differences",
    "href": "topics/discrete_predictor/index.html#stan-code-for-species-differences",
    "title": "Palmer penguins and discrete predictors",
    "section": "Stan code for species differences",
    "text": "Stan code for species differences\n\\[\n\\begin{align}\n\\text{Bill depth}_{\\text{sp}[i]} &\\sim \\text{Normal}(\\mu_{\\text{sp}[i]}, \\sigma) \\\\\n\\mu &\\sim \\text{Normal}(17, 2) \\\\\n\\sigma &\\sim \\text{Exponential}(2) \\\\\n\\end{align}\n\\]\n\nnormal_dist_rng_spp_forloop <- cmdstan_model(stan_file = \"topics/discrete_predictor/normal_dist_rng_spp_forloop.stan\")\n\nnormal_dist_rng_spp_forloop\n\ndata {\n  int N;\n  vector[N] measurements;\n  array[N] int<lower=1,upper=3> spp_id;\n}\nparameters {\n  vector[3] mu;\n  real<lower=0> sigma;\n}\nmodel {\n  for (i in 1:N){\n    measurements[i] ~ normal(mu[spp_id[i]], sigma);\n  }\n  mu ~ normal(17,2);\n  sigma ~ exponential(1);\n}\ngenerated quantities{\n  vector[N] yrep;\n  for (i in 1:N){\n    yrep[i] = normal_rng(mu[spp_id[i]], sigma);\n  }\n}\n\n\nThere’s a few differences to notice here:\n\nin the data block: We have a new input! A declaration of the array of integers at the top, saying if this is “species 1”, “species 2”, or “species 3”\nmu is a vector now. why?\nnotice the for-loop.\n\nDo we maybe add an illustration here of how vector indexing works?\nWe can write this model a different way as well:\n\nnormal_dist_rng_spp <- cmdstan_model(stan_file = \"topics/discrete_predictor/normal_dist_rng_spp.stan\")\n\nnormal_dist_rng_spp\n\ndata {\n  int N;\n  vector[N] measurements;\n  array[N] int<lower=1,upper=3> spp_id;\n}\nparameters {\n  vector[3] mu;\n  real<lower=0> sigma;\n}\nmodel {\n  measurements ~ normal(mu[spp_id], sigma);\n  mu ~ normal(17,2);\n  sigma ~ exponential(1);\n}\ngenerated quantities{\n  vector[N] yrep;\n  for (i in 1:N){\n    yrep[i] = normal_rng(mu[spp_id[i]], sigma);\n  }\n}\n\n\nThe only difference to the previous model is in the line with the for-loop, which is now replaced with a vectorized expression. This is faster to write and will run faster in Stan. However its not possible in every case. add a link to the Stan forum\n\nSampling the species model\nWe have to make a new data list, since we’ve added a new input: a vector of numbers 1, 2, or 3 that tells us if we are working with the first, second, or third species.\nwhich model to sample? here i’m doing the vectorized one just because\n\nlist_bill_dep_spp <- with(penguins_nobillNA,\n     list(\n       N = length(bill_depth_mm),\n       measurements = bill_depth_mm,\n       spp_id = as.numeric(as.factor(species))\n     )\n)\n     \nsamp_normal_dist_rng_spp <- normal_dist_rng_spp$sample(\n  data = list_bill_dep_spp, \n  parallel_chains = 4,\n  refresh = 0)\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 0.6 seconds.\nChain 2 finished in 0.7 seconds.\nChain 3 finished in 0.7 seconds.\nChain 4 finished in 0.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.6 seconds.\nTotal execution time: 0.8 seconds.\n\nsamp_normal_dist_rng_spp$draws(variables = c(\"mu\", \"sigma\")) |> \n  posterior::summarise_draws() |> \n  flextable::flextable()\n\n\nvariablemeanmediansdmadq5q95rhatess_bulkess_tailmu[1]18.34376318.343850.091489780.0945157518.19167018.4940000.99974815,234.2703,519.726mu[2]18.41388418.412400.136261920.1361026818.19059018.6411001.00017724,179.2503,084.304mu[3]14.98588014.986400.103612610.1052646014.81409515.1549051.00017144,091.1652,887.654sigma1.1228741.121340.044096080.044196311.0532761.1949621.00093014,778.9653,315.725\n\n\nand we can repeat the posterior checking from before:\n\nspp_yrep_draws <- samp_normal_dist_rng_spp$draws(variables = c(\"yrep\"))\nspp_draws_matrix <- posterior::as_draws_matrix(spp_yrep_draws)\n\nbayesplot::ppc_dens_overlay(y = list_bill_dep$measurements,\n                            yrep = head(spp_draws_matrix, 50))\n\n\n\n\nThe predicted distribution is now much more like the real data\nWe can also make figures for each individual species. Here we will move away from using bayesplot and try to visualize our posterior using the handy functions in the tidybayes package add a link\n\nlibrary(tidybayes)\nspp_draws_df <- posterior::as_draws_df(spp_yrep_draws)\n\nnormal_dist_post_samp <- tidybayes::gather_draws(samp_normal_dist_rng_spp,\n                        yrep[row_id], \n                        ndraws = 50)\n\nnormal_dist_post_samp |> \n  mutate(species = penguins_nobillNA$species[row_id]) |> \n  ggplot(aes(x = .value, colour = species)) + \n  geom_density(aes(group = .iteration), alpha = .1) + \n  facet_wrap(~species) + \n  geom_density(aes(x = bill_depth_mm),\n               data = penguins_nobillNA,\n               colour = \"black\") + \n  scale_colour_brewer(palette = \"Dark2\")\n\n\n\n\n\n\nExercises\n\nLevel 1\n\nrepeat this experience for another variable in the dataset. Does the same code work on bill length? What about body size? What would you change about the model (if anything)\nuse bayesplot to examine the fit of body size to these data.\n\n\n\nLevel 2\n\ngenerate some random groups of your own, with known means. How well does the model fit these data\nThe present model is fixed for exactly 3 groups. how would you change it for any number of groups?\n\n\n\nLevel 3\n\nthe function tidybayes::compose_data is a convenient way to set up your data for passing it into R. Try out this function. What does it produce for our dataset? How do you need to modify our Stan program so that it works for the output of tidybayes::compose_data?\nAs you can see, the model assumes the same sigma for all species. what if you relax this?\n\n\n\n\nOptional!\nTry this on your own data!"
  },
  {
    "objectID": "topics/01_data_simulation/data_simulation.html",
    "href": "topics/01_data_simulation/data_simulation.html",
    "title": "Data simulation",
    "section": "",
    "text": "Why would you want to? there are a few good reasons:\n\nUnderstand your priors. By simulating data from a model we get an idea of what priors actually mean scientifically. With all but the simplest models, this is essential\nDemonstrate your understanding of the model. If you can’t simulate data from a model, you probably don’t understand it!\nValidate that the model works correctly. If you can recover parameters when you know the truth, then we have more confidence that it will work correctly on real data."
  },
  {
    "objectID": "topics/01_data_simulation/data_simulation.html#watching-for-birds",
    "href": "topics/01_data_simulation/data_simulation.html#watching-for-birds",
    "title": "Data simulation",
    "section": "Watching for birds",
    "text": "Watching for birds\nLet’s start by simulating a simple dataset with one parameter: the number of birds each of us is going to see on a hike today.\nWhat kind of numbers do we expect to get? what is a reasonable limit to how many we would see?\n\nSimulation in R\nlet’s simulate from a poisson distribution. As you probably know, the poisson in R is just rpois. Every statistical distribution that is in R (which is a lot! almost all! ) has four functions. For a distribution called dist, they are:\n\nrdist = the distribution functions\nqdist = the quantile functions\npdist = the probability density function\nddist the density function\n\nLet’s begin by simulating data in R\n\nn_people <- 23\nobservations <- rpois(n_people, lambda = 20)\n\nhist(observations)\n\n\n\n\nWe can do the same process in the programming language Stan\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /Users/amacdonald/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\n\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n\npoisson_simulation <- cmdstan_model(stan_file = \"topics/01_data_simulation/poisson_simulation.stan\")\n\npoisson_simulation\n\ndata {\n  int<lower=0> n_people;\n  real avg_observed;\n}\ngenerated quantities {\n  // an array -- like a list in R\n  array[n_people] int<lower=0> observations;\n  \n  for (i in 1:n_people){\n    observations[i] = poisson_rng(avg_observed);\n  }\n}\n\n\n\ncompare and contrast the R and Stan formulations\nintro to Stan syntax\n\n\npoisson_simulation$sample(data = list(n_people = 23,\n                                      avg_observed = 19.5),\n                          fixed_param = TRUE)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 1 Iteration: 100 / 1000 [ 10%]  (Sampling) \nChain 1 Iteration: 200 / 1000 [ 20%]  (Sampling) \nChain 1 Iteration: 300 / 1000 [ 30%]  (Sampling) \nChain 1 Iteration: 400 / 1000 [ 40%]  (Sampling) \nChain 1 Iteration: 500 / 1000 [ 50%]  (Sampling) \nChain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 2 Iteration: 100 / 1000 [ 10%]  (Sampling) \nChain 2 Iteration: 200 / 1000 [ 20%]  (Sampling) \nChain 2 Iteration: 300 / 1000 [ 30%]  (Sampling) \nChain 2 Iteration: 400 / 1000 [ 40%]  (Sampling) \nChain 2 Iteration: 500 / 1000 [ 50%]  (Sampling) \nChain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 3 Iteration: 100 / 1000 [ 10%]  (Sampling) \nChain 3 Iteration: 200 / 1000 [ 20%]  (Sampling) \nChain 3 Iteration: 300 / 1000 [ 30%]  (Sampling) \nChain 3 Iteration: 400 / 1000 [ 40%]  (Sampling) \nChain 3 Iteration: 500 / 1000 [ 50%]  (Sampling) \nChain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 4 Iteration: 100 / 1000 [ 10%]  (Sampling) \nChain 4 Iteration: 200 / 1000 [ 20%]  (Sampling) \nChain 4 Iteration: 300 / 1000 [ 30%]  (Sampling) \nChain 4 Iteration: 400 / 1000 [ 40%]  (Sampling) \nChain 4 Iteration: 500 / 1000 [ 50%]  (Sampling) \nChain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.7 seconds.\n\n\n         variable  mean median   sd  mad    q5   q95 rhat ess_bulk ess_tail\n observations[1]  19.48  19.00 4.38 4.45 13.00 27.00 1.00     4235     3960\n observations[2]  19.51  19.00 4.40 4.45 13.00 27.00 1.00     3806     3632\n observations[3]  19.67  19.00 4.47 4.45 13.00 27.00 1.00     4170     3829\n observations[4]  19.53  19.00 4.35 4.45 13.00 27.00 1.00     3827     4003\n observations[5]  19.38  19.00 4.41 4.45 12.00 27.00 1.00     3630     3159\n observations[6]  19.43  19.00 4.43 4.45 12.00 27.00 1.00     4021     4033\n observations[7]  19.48  19.00 4.39 4.45 13.00 27.00 1.00     4136     3827\n observations[8]  19.55  19.00 4.45 4.45 13.00 27.00 1.00     3875     3756\n observations[9]  19.47  19.00 4.41 4.45 12.00 27.00 1.00     4165     3994\n observations[10] 19.41  19.00 4.44 4.45 12.00 27.00 1.00     3985     4005\n\n # showing 10 of 23 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)"
  },
  {
    "objectID": "topics/01_data_simulation/data_simulation.html#write-down-model",
    "href": "topics/01_data_simulation/data_simulation.html#write-down-model",
    "title": "Data simulation",
    "section": "Write down model",
    "text": "Write down model"
  },
  {
    "objectID": "topics/01_data_simulation/data_simulation.html#fit-model-to-a-simulation",
    "href": "topics/01_data_simulation/data_simulation.html#fit-model-to-a-simulation",
    "title": "Data simulation",
    "section": "Fit model to a simulation",
    "text": "Fit model to a simulation"
  },
  {
    "objectID": "topics/01_data_simulation/data_simulation.html#learning-how-to-plot-a-posterior",
    "href": "topics/01_data_simulation/data_simulation.html#learning-how-to-plot-a-posterior",
    "title": "Data simulation",
    "section": "learning how to plot a posterior",
    "text": "learning how to plot a posterior\nNow we can move on to the second step outlined above: we can just fit the same data to our model, vice versa, and see if we can recover that parameter."
  },
  {
    "objectID": "topics/01_data_simulation/data_simulation.html#r-based-alternatives",
    "href": "topics/01_data_simulation/data_simulation.html#r-based-alternatives",
    "title": "Data simulation",
    "section": "R based alternatives",
    "text": "R based alternatives\nIn R, there are several ways to do it: first, we can use R do it in two ways: fitdistr, and glm.\nThen we do the same thing in Stan.\nThen we look to see if we have recovered our parameter.\nThe next steop in visualization, which we also do with this simple model."
  },
  {
    "objectID": "topics/secret_weapon.html",
    "href": "topics/secret_weapon.html",
    "title": "Summarizing many univariate models",
    "section": "",
    "text": "We’ve already looked at univariate models. When we fit the same model to multiple different groups, we don’t expect the same values for all the coefficients. Each thing we are studying will respond to the same variable in different ways.\nHierarchial models represent a way to model this variation, in ways that range from simple to complex.\nBefore we dive in with hierarchical structure, let’s build a bridge between these two approaches.\nThis is useful to help us understand what a hierarchical model does.\nHowever it is also useful from a strict model-building perspective – so useful that Andrew Gelman calls it a “Secret Weapon” tk link\nTo keep things simple and univariate, let’s consider only water:\nFirst, a quick word about centering and scaling a predictor variable:\nsome things to notice about this figure:\nAs you can see, some of these estimates are high, others low. We could also plot these as histograms to see this distribution.\nOnce again, the two parameters of this model represent:"
  },
  {
    "objectID": "topics/secret_weapon.html#say-it-in-stan",
    "href": "topics/secret_weapon.html#say-it-in-stan",
    "title": "Summarizing many univariate models",
    "section": "Say it in Stan",
    "text": "Say it in Stan\nThe above tidyverse approach is very appealing and intuitive, but we can also do the same procedure in Stan."
  },
  {
    "objectID": "topics/secret_weapon.html#modelling-variation-in-slopes",
    "href": "topics/secret_weapon.html#modelling-variation-in-slopes",
    "title": "Summarizing many univariate models",
    "section": "Modelling variation in slopes",
    "text": "Modelling variation in slopes\nClearly there is variation among species in the values of these parameters. Like all variation, we can develop a scientific model to describe it. The simplest model we’ll consider is a simple univariate distribution.\n\nsuppressPackageStartupMessages(library(cmdstanr))\n\nlogistic_bern_glm <- cmdstan_model(\n  stan_file = here::here(\"topics/secret_weapon_univariate.stan\"), \n  pedantic = TRUE)\n\nmite_bin <- mite\nmite_bin[mite_bin>0] <- 1\n\nlogistic_bern_glm$sample(data = list(\n  Nsites = nrow(mite_bin),\n  K = 2,\n  S = ncol(mite_bin),\n  x = cbind(1, with(mite.env, (WatrCont - mean(WatrCont))/100)),\n  y = as.matrix(mite_bin)\n))\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 9.2 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 9.3 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 10.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 12.8 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 10.3 seconds.\nTotal execution time: 42.0 seconds.\n\n\n variable     mean   median   sd  mad       q5      q95 rhat ess_bulk ess_tail\n   lp__   -1171.18 -1170.78 8.32 8.07 -1185.34 -1157.97 1.00      643     1511\n   z[1,1]     1.67     1.65 0.36 0.36     1.11     2.29 1.00     1214     2032\n   z[2,1]     0.04     0.04 0.39 0.37    -0.62     0.67 1.00     2184     2490\n   z[1,2]    -0.41    -0.40 0.26 0.25    -0.86     0.00 1.00      839     1684\n   z[2,2]    -0.92    -0.90 0.43 0.41    -1.68    -0.26 1.00     2123     2361\n   z[1,3]     2.06     2.04 0.42 0.41     1.41     2.80 1.00     1256     2335\n   z[2,3]    -0.10    -0.09 0.42 0.40    -0.81     0.58 1.00     2376     2473\n   z[1,4]    -0.62    -0.61 0.28 0.28    -1.09    -0.17 1.00      706     1606\n   z[2,4]    -1.04    -1.02 0.45 0.44    -1.80    -0.36 1.00     1918     2508\n   z[1,5]    -1.07    -1.06 0.32 0.32    -1.61    -0.57 1.01      770     1442\n\n # showing 10 of 145 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n\n\nlet’s take a look at these values:\n\ndata(\"mite.xy\", package = \"vegan\")\nmite.xy\n\n      x   y\n1  0.20 0.1\n2  1.00 0.1\n3  1.20 0.3\n4  1.40 0.5\n5  2.40 0.7\n6  1.80 0.9\n7  0.05 1.1\n8  2.00 1.3\n9  2.00 1.5\n10 1.20 1.7\n11 2.40 1.9\n12 0.20 2.1\n13 0.40 2.1\n14 2.00 2.3\n15 2.20 2.3\n16 0.05 2.7\n17 0.20 2.7\n18 2.20 2.7\n19 2.40 2.7\n20 1.20 2.9\n21 0.05 3.1\n22 1.40 3.1\n23 2.40 3.1\n24 0.20 3.5\n25 1.20 3.7\n26 0.80 3.9\n27 1.60 3.9\n28 0.20 4.1\n29 0.80 4.1\n30 1.80 4.5\n31 0.20 4.7\n32 1.40 4.7\n33 0.60 5.3\n34 1.00 5.3\n35 2.40 5.3\n36 1.40 5.5\n37 1.80 5.5\n38 0.40 5.9\n39 1.00 5.9\n40 1.80 5.9\n41 2.00 5.9\n42 0.05 6.1\n43 0.20 6.1\n44 0.40 6.1\n45 1.20 6.1\n46 1.60 6.1\n47 1.60 6.3\n48 0.40 6.5\n49 1.80 6.7\n50 0.60 6.9\n51 2.00 7.1\n52 0.05 7.3\n53 0.40 7.3\n54 1.40 7.5\n55 2.20 7.5\n56 0.20 7.9\n57 1.60 7.9\n58 2.40 7.9\n59 0.05 8.1\n60 1.20 8.1\n61 1.40 8.1\n62 2.00 8.1\n63 1.60 8.5\n64 1.60 8.7\n65 1.00 8.9\n66 1.60 8.9\n67 2.40 9.1\n68 2.20 9.3\n69 1.80 9.5\n70 0.40 9.7\n\nnrow(mite)\n\n[1] 70"
  },
  {
    "objectID": "topics/01_simulation/index.html",
    "href": "topics/01_simulation/index.html",
    "title": "Data simulation",
    "section": "",
    "text": "Before starting work on real data, we are going to begin by learning how to make up some of our own. There are at least three reasons why this is a good idea:"
  },
  {
    "objectID": "topics/01_simulation/index.html#simple-exercise-in-simulation",
    "href": "topics/01_simulation/index.html#simple-exercise-in-simulation",
    "title": "Data simulation",
    "section": "Simple exercise in simulation",
    "text": "Simple exercise in simulation\nLet’s imagine we are taking a walk as a group today at the beautiful SBL. What is the number of birds each of us is going to see on our hike?\n\n\n\n\n\n\nNote\n\n\n\nSimulating data really helps a scientist to ask an important question: “Where do my numbers come from?”. What kind of numbers do we expect to get? Do they have an upper limit? a lower limit? What kind of observation would be a little suprising? VERY surprising?\n\n\n\nWhat is the process\nWe might imagine that each one of us is likely to see about the same number of birds. We know our data (number of birds) is going to be a positive integer: 0 or more birds\n\\[\n\\begin{align}\n\\text{Number of Birds} &\\sim \\text{Poisson}(\\lambda) \\\\\n\\lambda &= 20\n\\end{align}\n\\]\n$$ \\[\\begin{align}\n\\text{Number of Birds} &\\sim \\text{Poisson}(\\lambda_i) \\\\\n\\lambda_i &= \\mu \\\\\n\n\\end{align}\\] $$\n\nabd ~ 1 + (1 | person)\n\nabd ~ 1 + (1 | person)\n\n\n\n\nSimulation in R\nlet’s simulate from a poisson distribution.\n\nset.seed(1234)\nn_people <- 21\nrpois(n_people, lambda = 20)\n\n [1] 14 21 21 16 22 17 24 17 17 12 20 24 19 17 23 17 20 17 20 19 23\n\n\nas you probably know, to draw random numbers in R we use the function rpois\nEvery statistical distribution that is in R (which is a lot! almost all! ) has a distirbution has four functions. of the distribution is called dist, then they are:\nrdist = the distribution functions qdist = the quantile functions pdist = the probability density function ddist the density function\n\n\n\n\n\n\nNote\n\n\n\nIn these simulations we can see that we are expressing ourselves with a sort of great, big shrug: we have no idea what these numbers might be, and so we are working to just make up fake ones. we start with very little – with literally no information – about what our data might be when we see it. for a bayeisan, there is no practical difference between data and parameters in a model\nwhat makes a person and approach Bayesian is not the use of Bayes rule. Bayes rule is just a fact about conditional probability, which everyone uses regardless of their framework for scientific inference. no, to be bayesian is to use probability to measure uncertainty.\n\n\n.. plot it.."
  },
  {
    "objectID": "topics/01_simulation/index.html#simulating-data-in-stan",
    "href": "topics/01_simulation/index.html#simulating-data-in-stan",
    "title": "Data simulation",
    "section": "Simulating data in Stan",
    "text": "Simulating data in Stan\nwrite model walk through it"
  },
  {
    "objectID": "topics/01_simulation/index.html#parameter-recovery",
    "href": "topics/01_simulation/index.html#parameter-recovery",
    "title": "Data simulation",
    "section": "parameter recovery",
    "text": "parameter recovery\nOk so now we can see our first simple stan model! we are using this powerful tool to draw forty random numbers.\nin R : fitdistr, glm\nNow we can move on to the second step outlined above: we can just fit the same data to our model, vice versa, and see if we can recover that parameter.\nIn R, there are several ways to do it: first, we can use R do it in two ways: fitdistr, and glm.\nThen we do the same thing in Stan.\nThen we look to see if we have recovered our parameter.\nThe next steop in visualization, which we also do with this simple model."
  },
  {
    "objectID": "topics/day_1.html#content",
    "href": "topics/day_1.html#content",
    "title": "Day 1",
    "section": "Content",
    "text": "Content\nThe Secret Weapon\nregression with discrete predictors\n\nAfternoon practical exercises"
  },
  {
    "objectID": "topics/day_1.html#course-setup-information",
    "href": "topics/day_1.html#course-setup-information",
    "title": "Day 1",
    "section": "Course setup information",
    "text": "Course setup information\n\nsite information\nplagiarism"
  },
  {
    "objectID": "topics/day_1.html#simulation",
    "href": "topics/day_1.html#simulation",
    "title": "Day 1",
    "section": "Simulation",
    "text": "Simulation"
  },
  {
    "objectID": "topics/day_1.html#quantifying-uncertainty",
    "href": "topics/day_1.html#quantifying-uncertainty",
    "title": "Day 1",
    "section": "Quantifying uncertainty",
    "text": "Quantifying uncertainty"
  },
  {
    "objectID": "topics/day_1.html#resampling",
    "href": "topics/day_1.html#resampling",
    "title": "Day 1",
    "section": "Resampling",
    "text": "Resampling\nIn frequentist models, we can use the variance covariance matrix of parameters to resample new parameters values. This lets us propagate uncertainty from the estimated parameters to the predicted relationship.\nLet’s demonstrate this with one specific mite:\n\nlrug_water <- mite_water |> \n  filter(sp == \"LRUG\")\n\nlrug_glm <- glm(pa ~ water, data = lrug_water, family = \"binomial\")\n\nNow, with our model object, we can create the resampling distribution of the model predicitons:\n\n# Set seed\nset.seed(42) # The answer !\n\n# a sequence along the range of water values in the data\npredVal <- seq(from = min(lrug_water$water),\n               to = max(lrug_water$water),\n               length.out = 30)\n\nn_resamp <- 500\n\n# Result object\nresampModel <- array(NA_real_,\n                   dim = c(length(predVal), n_resamp))\n\n# Resample model parameters and calculate model predictions\nparamMean <- summary(lrug_glm)$coefficients[,1]\nparamCov <- summary(lrug_glm)$cov.unscaled\n\n# Resample model parameters\nparamSmpl <- MASS::mvrnorm(n_resamp, paramMean, paramCov)\n\n# Calculate model predictions using the resampled model parameters\nfor(j in 1:n_resamp){\n  resampModel[,j] <- binomial(link = \"logit\")$linkinv(\n    paramSmpl[j,1] + paramSmpl[j,2] * predVal)\n}\n\n# make a plot of these predictions\nmatplot(predVal, resampModel, type = \"l\", col = \"grey\", lty = 1)\n\n\n\n\nIf we want to find some kind of confidence interval for this line, we can take the quantiles of this resampling:\n\nlow <- apply(resampModel, 1, quantile, probs = .015)\nhigh <- apply(resampModel, 1, quantile, probs = .985)\n\n# plot\nwith(lrug_water, plot(pa ~ water, pch = 21, bg = \"lightblue\"))\npolygon(c(predVal,rev(predVal)),\n        c(low,rev(high)), col=\"thistle\", border=NA)\nlines(predVal, \n      predict(lrug_glm, newdata = list(water = predVal), type = \"response\")\n      )\n\n\n\n\nWe can also do this in a tidyverse style, if you are more comfortable with that:\n\ntibble(predVal) |> \n  rowwise() |> \n  mutate(intercept = list(paramSmpl[,1]),\n         slope = list(paramSmpl[,2]),\n         prediction = list(intercept + slope*predVal),\n         prediction_probability = list(plogis(prediction)),\n         low  = quantile(prediction_probability, .015),\n         high = quantile(prediction_probability, .985)) |> \n  ggplot(aes(x = predVal, ymin = low, ymax = high)) + \n  geom_ribbon(fill = \"thistle\") + \n  theme_bw() + \n  ylim(c(0,1))"
  },
  {
    "objectID": "topics/day_1.html#bayesian-approach",
    "href": "topics/day_1.html#bayesian-approach",
    "title": "Day 1",
    "section": "Bayesian approach",
    "text": "Bayesian approach\nhere is a simple bayesian model to generate the same inference:\n\\[\n\\begin{align}\ny &\\sim \\text{Bernoulli}(p)\\\\\n\\text{logit}(p) &= \\alpha + X\\beta\\\\\n\\alpha &\\sim \\text{Normal}(-2.5, .5)\\\\\n\\beta &\\sim \\text{Normal}(0, .5)\\\\\n\\end{align}\n\\]\nnormally we would go through a careful process of checking our priors here. At this time we won’t because the point here is to show how the bayesian posterior includes uncertainty, not to demonstrate a full Bayes workflow.\nFirst we compile the model, then we’ll look at the Stan code:\n\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.5.3\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /Users/amacdonald/.cmdstan/cmdstan-2.31.0\n\n\n- CmdStan version: 2.31.0\n\n\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n\nlogistic_glm_stan <- cmdstan_model(stan_file = \"stan/logistic_bern_logit.stan\", \n                               pedantic = TRUE)\n\nlogistic_glm_stan\n\ndata {\n  int<lower=0> n;\n  vector[n] x;\n  array[n] int<lower=0,upper=1> y;\n}\nparameters {\n  real intercept;\n  real slope;\n}\nmodel {\n  y ~ bernoulli_logit(intercept + slope * x);\n  intercept ~ normal(-2.5, .5);\n  slope ~ normal(0, .5);\n}\n\n\nHere we see the same three parts of a Stan model that we have reviewed already:\n\ndata\nparameters\nprobability statements\n\nAs you can see, we are using a handy Stan function called bernoulli_logit. This function expects our prediction for the average to be on the logit scale, then applies the logit link function for us.\n\n\nAs a quick review, the logit equation, or inverse-log-odds, is written as \\[\n\\frac{e^\\mu}{1 + e^\\mu}\n\\] Which is also written as\n\\[\n\\frac{1}{1 + e^{-\\mu}}\n\\]\nStan expects our data as a list.\n\nlogistic_glm_stan_samples <- logistic_glm_stan$sample(\n  data = list(n = nrow(lrug_water),\n              y = lrug_water$pa,\n              x = lrug_water$water),\n  refresh = 0)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 1.1 seconds.\nChain 2 finished in 0.5 seconds.\nChain 3 finished in 0.7 seconds.\nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 3.2 seconds.\n\ncoef(lrug_glm)\n\n(Intercept)       water \n-2.48153943  0.00874349 \n\nlibrary(tidybayes)\n\nspread_rvars(logistic_glm_stan_samples, intercept, slope[]) |> \n  bind_cols(predVal = predVal) |> \n  mutate(pred = posterior::rfun(plogis)(predVal * slope + intercept)) |> \n  ggplot(aes(x = predVal, ydist = pred)) + \n  stat_dist_lineribbon() + \n  guides(fill = \"none\") + \n  ylim(c(0,1))\n\nWarning: Using the `size` aesthetic with geom_ribbon was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\nWarning: Unknown or uninitialised column: `linewidth`.\n\n\nWarning: Using the `size` aesthetic with geom_line was deprecated in ggplot2 3.4.0.\nℹ Please use the `linewidth` aesthetic instead.\n\n\nWarning: Unknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\n\n\n\n\n\n\nAlternative parameterization\nStan contains many functions intended to facilitate writing statistical models. Above, we used the function bernoulli_logit so that we could provide the expression for the average on the logit scale.  Stan also provides an even more efficient function that we can use; it is especially good when we have more than one predictor variable and a vector of slopes:This idea is the core concept of a GLM, or generalized linear model. Statistical distributions have parameters, but for most distributions these have constraints – only some values are “allowed”. For example, the only parameter of a Bernoulli distribution is \\(p\\), the probability of success. We respect this constraint by using a link function: we write an expression for the average of a distribution that can be any real number, and put it through a link function to get the value for \\(p\\).\n\n\n\n\n\n\nWarning\n\n\n\nPLEASE NOTE below you will see the relative path to the stan file (stan/logistic.stan). Immediately below you will see the Stan file content. You can copy and paste this to your own computer!\n\n\n\nsuppressPackageStartupMessages(library(cmdstanr))\n\nlogistic_bern_glm <- cmdstan_model(stan_file = \"stan/logistic.stan\", \n                               pedantic = TRUE)\n\nlogistic_bern_glm\n\ndata {\n  int<lower=0> N;\n  matrix[N, 1] x;\n  array[N] int<lower=0,upper=1> y;\n}\nparameters {\n  real intercept;\n  vector[1] slope;\n}\nmodel {\n  intercept ~ normal(-2.5, .5);\n  slope ~ normal(0, .5);\n  y ~ bernoulli_logit_glm(x, intercept, slope);\n}"
  },
  {
    "objectID": "topics/day_2.html#convergence-diagnostics",
    "href": "topics/day_2.html#convergence-diagnostics",
    "title": "Day 2",
    "section": "Convergence Diagnostics",
    "text": "Convergence Diagnostics"
  },
  {
    "objectID": "topics/day_2.html#model-validation-with-simulation",
    "href": "topics/day_2.html#model-validation-with-simulation",
    "title": "Day 2",
    "section": "Model validation with simulation",
    "text": "Model validation with simulation"
  },
  {
    "objectID": "topics/day_2.html#dags",
    "href": "topics/day_2.html#dags",
    "title": "Day 2",
    "section": "DAGs",
    "text": "DAGs\n\nforks, pipes and colliders\nsimulation from a DAG\ndemonstration of errors from disregarding DAGs"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course contents",
    "section": "",
    "text": "Introduction to the course and location\nData we’ll be using\nBayesian and MCMC\nStan and HMC\n\n\n\n\nData simulation in Ecology\nlunch activity: COUNT BIRDS!\nDiscrete predictors"
  },
  {
    "objectID": "index.html#day-2",
    "href": "index.html#day-2",
    "title": "Course contents",
    "section": "DAY 2:",
    "text": "DAY 2:\n\nSlides\n\nLinear models\nmatrix algebra\nSimple hierarchical models\nreturn to the group intercept model – abundance across plots\nsecret weapon – model for parameters\nmultilevel intercepts\nmultilevel slopes"
  },
  {
    "objectID": "index.html#day-3",
    "href": "index.html#day-3",
    "title": "Course contents",
    "section": "Day 3",
    "text": "Day 3\n\nLarger hierarchical models\nmodelling multiple intercepts – e.g. intercepts for site and species\nmodelling different slopes for each species\nmodelling multiple slopes and intercepts at the same time\nrandom intercepts with a fixed predictor"
  },
  {
    "objectID": "index.html#day-4",
    "href": "index.html#day-4",
    "title": "Course contents",
    "section": "Day 4",
    "text": "Day 4\n\nmodelling slopes and intercepts as correlated\nNC vs centered param\nintro to GPs"
  },
  {
    "objectID": "index.html#day-5",
    "href": "index.html#day-5",
    "title": "Course contents",
    "section": "Day 5",
    "text": "Day 5\n\nEverything everywhere all at once (60 to 90 minutes on the Full Models)\nlme4 paper (bates)"
  },
  {
    "objectID": "index.html#day-4-1",
    "href": "index.html#day-4-1",
    "title": "Course contents",
    "section": "Day 4",
    "text": "Day 4\n*gaussian process regression\n\nSlides to introduce Stan\nlinear models\n\nbidonia regression simulation\nsimulation – to measure uncertainty\nusing var-covar and simulating confidence intervals\n\nsimple l\n\nnotes: could we rephrase the model to have the central tendency and the sigma cf to baye methods\nTODOS: * need to edit the title slide for the"
  }
]