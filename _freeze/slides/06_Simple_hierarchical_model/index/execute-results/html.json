{
  "hash": "86067fc6de9bc73a49df8ba1a38c693a",
  "result": {
    "markdown": "---\ntitle: \"'Simple' hierarchical models\"\ntitle-slide-attributes: \n  data-background-image: ../img/bg.jpg\n  data-background-size: full\nauthor: \"Andrew MacDonald and Guillaume Blanchet and Vincent Tolon\"\ndate: \"2023-02-10\"\nexecute:\n  echo: true\nformat: \n  revealjs:\n    theme: [default]\n    logo: ../img/UdeS_logo_h_rgbHR.png\n    transition: slide\n    background-transition: fade\n---\n\n\n## \"Simple\" hierarchical model\n\nHere, we use the term \"simple\" in a rather loose way to discuss hierarchical models without any constrains, whether they are spatial, temporal, phylogenetic or others. \n\nFuthermore, for most of this lecture, we will focus on models with a Gaussian error term to develop the underlying theory. \n\nWhen we will have done this, it will be reasonably straight forward to move to non-Gaussian hierarchical model.\n\n\n## A (very !) general formulation\n\n::: {style=\"font-size: 0.68em\"}\nAs discuss yesterday, a linear model can be writen as\n\n$$\\mathbf{y}\\sim \\mathcal{MVN}(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma^2\\mathbf{I})$$\n\nwhere\n\n- $\\mathbf{y}$ is a vector quantifying a response variable of length $n$\n- $\\mathbf{X}$ is a matrix of explanatory variables with $n$ rows (samples) and $p$ columns (explanatory varaibles) \n- $\\boldsymbol{\\beta}$ is a vector $p$ pararameters weighting the importance of each explanatory variables in $\\mathbf{X}$\n- $\\sigma^2$ is a measure of variance of the error in the regression model\n- $\\mathbf{I}$ is an $n \\times n$ identity matrix \n:::\n\n## A (very !) general formulation\n\n::: {style=\"font-size: 0.8em\"}\nA hierarchical model is a generalization of the linear model such that \n\n$$(\\mathbf{y}|\\mathbf{b} )\\sim \\mathcal{MVN}(\\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{Z}\\mathbf{b}, \\sigma^2\\mathbf{I})$$\n:::\n::: {style=\"font-size: 0.68em\"}\n\nwhere\n\n- $\\mathbf{y}$ is a vector quantifying a response variable of length $n$\n- $\\mathbf{X}$ is a matrix of explanatory variables with $n$ rows (samples) and $p$ columns (explanatory variables) \n- $\\boldsymbol{\\beta}$ is a vector $p$ pararameters weighting the importance of each explanatory variables in $\\mathbf{X}$\n- $\\sigma^2$ is a measure of variance of the error in the regression model\n- $\\mathbf{I}$ is an $n \\times n$ identity matrix \n\n:::: {style=\"color: blue\"}\n- $\\mathbf{Z}$ is another matrix of explanatory variables with $n$ rows (samples) and $q$ columns (explanatory variables) \n- $\\mathbf{b}$ is a vector $q$ pararameters weighting the importance of each explanatory variables in $\\mathbf{Z}$\n::::\n:::\n\n## A (very !) general formulation\n\n::: {style=\"font-size: 0.8em\"}\nA hierarchical model is a generalization of the linear model such that \n\n$$(\\mathbf{y}|\\mathbf{b} )\\sim \\mathcal{MVN}(\\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{Z}\\mathbf{b}, \\sigma^2\\mathbf{I})$$\nWhat is also noticeable in this model is the conditional relationship between $\\mathbf{y}$ and $\\mathbf{b}$.\n\nSpecifically, in this formulation, \n\n$$\\mathbf{b}\\sim \\mathcal{MVN}(\\mathbf{0}, \\mathbf{\\Sigma})$$\nwhere $\\mathbf{\\Sigma}$ is a covariance matrix.\n\nBased on this  general formulation, we can now define all unconstrained hierarchical models.\n:::\n\n\n## The \"`|`\"\n\n::: {style=\"font-size: 0.8em\"}\nMost of you have probably already used the packages `lme4` or `brms` to build hierarchical models and so you have used the `|` to include a hierachy in your model.\n\nBut do you know what the underlying mathematical structure of the model you built look like ? Does it really answer the question you were asking ?\n:::\n\n![](https://www.i2symbol.com/pictures/emojis/2/1/4/4/21445641aeaca6c4436579b3fa30772b_384.png){fig-align=\"center\" width=20%}\n\n::: {style=\"font-size: 0.8em\"}\nLet's look at different `lme4` models to learn about some basic (and not so basic!) hierarchical models.\n:::\n\n## A bit of notation\n\nBefore we get into writing math, we need to define a bit of notation in addition of the one we have used so far.\n\nSpecifically, when define a hierarchy in a model, it is common to do this using at least one factor. Mathematically, we will define the different level of a factor in a model by a subscript. \n\nWe will use square brackets to define the level of interest\n\n### Example\n\n$$\\mathbf{Z}_{f[l]}$$\nThis means that, within $\\mathbf{Z}$, we focus on $l^{\\text{th}}$ level of factor $f$.\n\n## Hierarchy on the intercept\n\n::: {style=\"font-size: 0.8em\"}\n`lme4` notation used `y ~ (1 | f)` or `y ~ 1 + (1 | f)`\n\nThis model assumes there is a hierarchy solely on the intercept.\n\nMathematically, it can be translated to \n\n$$\\mathbf{y} \\sim \\mathcal{MVN}(\\mathbf{b}_{f[l]},\\sigma^2\\mathbf{I}) \\quad \\forall\\quad l = 1\\dots k$$\nor \n\n$$y_i = b_{{f_i[l]}} + \\varepsilon \\quad \\forall\\quad l = 1\\dots k\\,\\,\\,\\,\\text{and}\\,\\,\\,i = 1\\dots n$$\nIn words, this means that the model values $b$ will change for a sample $i$ only when the level $l$ of the factor $f$ changes. \n\nThis is because in this model\n\n$$\\mathbf{b} \\sim \\mathcal{N}(0, \\sigma^2_f)$$\n:::\n\n## Hierarchy on the intercept\n### Stan code for this model\n\n::: {style=\"margin-top: 200px; font-size: 2.5em; color: red;\"}\nFor Andrew?\n:::\n\n## Hierarchy on the intercept\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n## Hierarchy on the slopes\n\n::: {style=\"font-size: 0.7em\"}\n`lme4` notation : `y ~ 1 + (x | f)`\n\nThis model assumes there is a hierarchy on the parameters associated to variable `x`.\n\nMathematically, it can be translated to \n\n$$\\mathbf{y} \\sim \\mathcal{MVN}(\\beta_0 + \\mathbf{Z}\\mathbf{b}_{f[l_f]},\\sigma^2\\mathbf{I}) \\quad\\forall\\quad l_f = 1\\dots k_f$$\nor \n\n$$y_i = \\beta_0 + b_{f[l_f]}z_i + \\varepsilon \\quad\\forall\\quad l_f = 1\\dots k_f\\,\\,\\,\\,\\text{and}\\,\\,\\,i = 1\\dots n$$\nIn words, this means that the weight on variable $z$ will change for a sample $i$ only when the level $l$ of the factor $f$ changes. \n\nThis is because in this model\n\n$$\\mathbf{b} \\sim \\mathcal{N}(0, \\sigma^2_f)$$\n:::\n\n## Hierarchy on the slopes\n### Stan code for this model\n\n::: {style=\"margin-top: 200px; font-size: 2.5em; color: red;\"}\nFor Andrew?\n:::\n\n\n## Hierarchy on the slopes\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n## Hierarchy on intercept and slope\n\nMathematically speaking, what are the differences between having a hierarchy on the intercept and a slope ? Any idea ?\n\n![](https://www.i2symbol.com/pictures/emojis/4/c/e/b/4ceb092d154efb14f6913cb5e332f6da_384.png){fig-align=\"center\" width=20%}\n\n## Hierarchy on intercept and slope\n\nAnswer : Very little !\n\n:::{style=\"font-size: 0.8em\"}\n\nActually, if we return the way $\\mathbf{b}$ is defined we see that in both case it is defined as \n\n$$\\mathbf{b} \\sim \\mathcal{N}(0, \\sigma^2_f)$$\nwith the sole difference that $\\mathbf{b}$ linked to an explanatory variable when the hierarchy is on the slope, while when the hierarchy is on the intercept it is not linked to any explanatory variable.\n\nWell... Actually... When a hierarchy is applied on the intercept it is technically associated to a **constant** explanatory variable.\n:::\n\n## How many levels ?\n\nA common question that often gets asked is : \n\n\"How many level is enough ?\"\n\nThis is a simple questions that sadly does not have a simple answer.\n\n![](https://www.i2symbol.com/pictures/emojis/7/e/1/8/7e1820e72993db112424b5a92e1d40d7_384.png){fig-align=\"center\" width=20%}\n\n## How many levels ?\n\nIn these types of models we are interested in estimating the variance parameter $\\sigma^2_f$ in \n\n$$\\mathbf{b} \\sim \\mathcal{N}(0, \\sigma^2_f)$$\nto get the best estimation of $\\mathbf{b}$. \n\nSo, another way to ask this question is \"What is the minimum number of samples needed to properly estimate the variance of a Gaussian distribution?\" \n\nHowever, in the context of how we defined hierarchical models, a sample amounts to being the level of a factor.\n\n## How many levels ?\n\nWhat is the minimum number of samples needed to properly estimate the variance of a Gaussian distribution?\n\n### Is 3 enough ?\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=768}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\nTrue variance : 0.25\n\nEstimated variance : 0.234\n:::\n::::\n\n\n## How many levels ?\n\nWhat is the minimum number of samples needed to properly estimate the variance of a Gaussian distribution?\n\n### Maybe 5 ?\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=768}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\nTrue variance : 0.25\n\nEstimated variance : 0.12\n:::\n::::\n\n## How many levels ?\n\nWhat is the minimum number of samples needed to properly estimate the variance of a Gaussian distribution?\n\n### Or 10 ?\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=768}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\nTrue variance : 0.25\n\nEstimated variance : 0.174\n:::\n::::\n\n\n## How many levels ?\n\nWhat is the minimum number of samples needed to properly estimate the variance of a Gaussian distribution?\n\n### Or 50 ?\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=768}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\nTrue variance : 0.25\n\nEstimated variance : 0.331\n:::\n::::\n\n\n## How many levels ?\n\nWhat is the minimum number of samples needed to properly estimate the variance of a Gaussian distribution?\n\n### Or 100 ?\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=768}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\nTrue variance : 0.25\n\nEstimated variance : 0.271\n:::\n::::\n\n\n## How many levels ?\n\nWhat is the minimum number of samples needed to properly estimate the variance of a Gaussian distribution?\n\n### Or 1000 ?\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=768}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\nTrue variance : 0.25\n\nEstimated variance : 0.251\n:::\n::::\n\n## How many levels ?\n\nThere is a consensus among researchers working intimately with hierarchical that when the interest is to properly estimate the variance parameter $\\sigma^2$, 5 or 6 levels is the extreme minimum.\n\n::: {style=\"font-size: 0.75em\"}\nIn the book *Richly Parameterized Linear Models: Additive, Time Series, and Spatial Models Using Random Effects*, James S. Hodges (2016) makes this very thoughtful statement : \n\n:::: {style=\"color: blue\"}\n\"Treating factors with small numbers of levels as random will in the best case lead to very small and/or imprecise estimates of random effects; in the worst case it will lead to various numerical difficulties such as lack of convergence, zero variance estimates, etc.\"\n::::\n:::\n\n## How many levels ?\n\nSo, what to do if the number of level is not high enough for your comfort ?\n\nYou can still use the hierarchy in your model but focus on the mean of the levels instead of the variance.\n\nHow does this translate mathematically, with what we have seen so far ?\n\n![](https://www.i2symbol.com/pictures/emojis/4/c/e/b/4ceb092d154efb14f6913cb5e332f6da_384.png){fig-align=\"center\" width=20%}\n\n## Hierarchy on the intercept's mean\n\n::: {style=\"font-size: 0.7em\"}\n$$\\mathbf{y} \\sim \\mathcal{MVN}(\\boldsymbol{\\beta}_{f[l]},\\sigma^2\\mathbf{I}) \\quad \\forall\\quad l = 1\\dots k$$\nor \n\n$$y_i = \\beta_{f_i[l]} + \\varepsilon \\quad \\forall\\quad l = 1\\dots k\\,\\,\\,\\,\\text{and}\\,\\,\\,i = 1\\dots n$$\nIn this model, we assume that $\\boldsymbol{\\beta}_{f[l]}$ is distributed as \n\n$$\\boldsymbol{\\beta}_{f[l]} \\sim \\mathcal{N}(\\mu_{f[l]}, \\sigma^2_{f[l]})$$\nIn words, this means that all the samples **within** the $l^\\text{th}$ level of factor $f$ are used to estimate $\\boldsymbol{\\beta}_{f[l]}$. \n\nBy developping our model this way, we focus on estimating the mean of groups in the hierarchy instead of only the variance. \n:::\n\n## Hierarchy on the intercept's mean\n\n::: {style=\"font-size: 0.7em\"}\nLet's take a deeper look at \n$$\\boldsymbol{\\beta}_{f[l]} \\sim \\mathcal{N}(\\mu_{f[l]}, \\sigma^2_{f[l]})$$\nWhen we study this way of sampling $\\boldsymbol{\\beta}_{f[l]}$, although our interest is more on $\\mu_{f[l]}$, we also have to estimate the variance term $\\sigma^2_{f[l]}$.\n\nTechnically, we can sample all $\\boldsymbol{\\beta}_{f[l]}$ independently, however, using multivariate Gaussian distribution, we can sample the $\\boldsymbol{\\beta}_{f}$ for all levels of the factor in one go as\n\n$$\\boldsymbol{\\beta}_{f} \\sim \\mathcal{MVN}(\\boldsymbol{\\mu}_{f}, \\mathbf{D}_f)$$\nwhere \n\n- $\\boldsymbol{\\mu}_{f}$ is a vector of $k$ means, one for each level of the factor\n- $\\mathbf{D}_f$ is a $k\\times k$ diagonal matrix with variance term on the diagonal\n\n:::\n\n## Hierarchy on the intercept's mean\n\n::: {style=\"font-size: 0.7em\"}\nThe structure of matrix $\\mathbf{D}_f$ can be considered in two different ways in \n\n$$\\boldsymbol{\\beta}_{f} \\sim \\mathcal{MVN}(\\boldsymbol{\\mu}_{f}, \\mathbf{D}_f)$$\n\nWritten in the general form as we did in the equation above, we assume that all variance on the diagonal are potentially different. Or in other words, the variance in each group is assumed to be different\n::: \n::: {style=\"font-size: 0.6em\"}\n$$\\mathbf{D}_f = \\begin{bmatrix}\n\t\t\t\t\\sigma^2_{f[1]} & 0 & \\dots & 0 & \\dots & 0\\\\\n\t\t\t\t0 & \\sigma^2_{f[2]} & \\dots & 0 & \\dots & 0\\\\\n\t\t\t\t\\vdots & \\vdots & \\ddots & \\vdots & & \\vdots\\\\\n\t\t\t  0 & 0 & \\dots & \\sigma^2_{f[l]} & \\dots & 0\\\\\n\t\t    \\vdots & \\vdots & & \\vdots & \\ddots & \\vdots\\\\\n\t\t    0 & 0 & \\dots & 0 & \\dots & \\sigma^2_{f[k]}\\\\\n\t\t\\end{bmatrix}$$\n:::\n\n## Hierarchy on the intercept's mean\n\n::: {style=\"font-size: 0.7em\"}\nHowever, it can be assumed to be all the same variance regardless of the group considered \n\n::: {style=\"font-size: 0.68em\"}\n$$\\mathbf{D}_f = \\begin{bmatrix}\n\t\t\t\t\\sigma^2_{f} & 0 & \\dots & 0 & \\dots & 0\\\\\n\t\t\t\t0 & \\sigma^2_{f} & \\dots & 0 & \\dots & 0\\\\\n\t\t\t\t\\vdots & \\vdots & \\ddots & \\vdots & & \\vdots\\\\\n\t\t\t  0 & 0 & \\dots & \\sigma^2_{f} & \\dots & 0\\\\\n\t\t    \\vdots & \\vdots & & \\vdots & \\ddots & \\vdots\\\\\n\t\t    0 & 0 & \\dots & 0 & \\dots & \\sigma^2_{f}\\\\\n\t\t\\end{bmatrix}$$\n:::\n\nIn this case, $\\boldsymbol{\\beta}_{f} \\sim \\mathcal{MVN}(\\boldsymbol{\\mu}_{f}, \\mathbf{D}_f)$\ncan be rewritten as \n$$\\boldsymbol{\\beta}_{f} \\sim \\mathcal{MVN}(\\boldsymbol{\\mu}_{f}, \\sigma^2_{f}\\mathbf{I})$$\n**Note**: This is essentially the same thing as a one-way analysis of variance.\n\n:::\n\n## Hierarchy on the intercept's mean\n### Stan code\n\n::: {style=\"margin-top: 200px; font-size: 2.5em; color: red;\"}\nFor Andrew?\n:::\n\n## Hierarchy on the intercept's mean\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n## Hierarchy on the slope's mean\n\n::: {style=\"font-size: 0.7em\"}\nDevelopping a hierarchy on the slope's mean translate mathematically in a very similar way as it does for the intercept. \n\n$$\\mathbf{y} \\sim \\mathcal{MVN}(\\boldsymbol{\\beta}_0+\\mathbf{X}\\boldsymbol{\\beta}_{f[l]},\\sigma^2\\mathbf{I}) \\quad \\forall\\quad l = 1\\dots k$$\nor \n\n$$y_i = \\beta_0 + \\beta_{f_i[l]}x_i + \\varepsilon \\quad \\forall\\quad l = 1\\dots k\\,\\,\\,\\,\\text{and}\\,\\,\\,i = 1\\dots n$$\nIn this model, we assume that $\\boldsymbol{\\beta}_{f[l]}$ is distributed as \n\n$$\\boldsymbol{\\beta}_{f[l]} \\sim \\mathcal{N}(\\mu_{f[l]}, \\mathbf{D}_{f[l]})$$\nIn words, this means that all the samples **within** the $l^\\text{th}$ level of factor $f$ are used to estimate $\\boldsymbol{\\beta}_{f[l]}$. \n\nBy developping our model this way, we focus on estimating the average slope for each group in the hierarchy instead of only the variance. \n:::\n\n\n## Hierarchy on the slope's mean\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n## Hierarchy on the slope's mean\n### Stan code\n\n::: {style=\"margin-top: 200px; font-size: 2.5em; color: red;\"}\nFor Andrew?\n:::\n\n## Tracking the estimated parameters\n\n::: {style=\"font-size: 0.8em;\"}\nAs can be seen, it is important in hierarchical model to track the different parameters that are estimated to make sure we can make proper inferences with our model.\n\nHowever, we need to be careful because the notation used can play trick on us. This is especially true when using matrix notation. \n\nFor example, in \n\n$$\\boldsymbol{\\beta}_{f[l]} \\sim \\mathcal{N}(\\mu_{f[l]}, \\mathbf{D}_{f[l]})$$\nthe number of levels are not explicitly defined and it is not clear if $\\mathbf{D}_{f[l]}$ includes the same variance value on the diagonal or different ones. \n\nIn any case, make sure to keep track of the estimated parameters so that you can better understand the limits of the model you are building and using. \n\n:::\n\n## Choosing the right model\n\nAlthough these different models are mathematically quite similar, they approach very different biological questions. \n\nA comparison of the different figures caricaturizing how each model works should give a good insight about what each model can do.\n\nIt is thus important to make sure you design your biological question well so that deciding on which model to use is reasonably straight forward.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}