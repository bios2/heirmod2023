{
  "hash": "67a33cda835c2068ca6d36e6042324a6",
  "result": {
    "markdown": "---\ntitle: \"Complex hierarchical models\"\ntitle-slide-attributes: \n  data-background-image: ../img/bg.jpg\n  data-background-size: full\nauthor: \"Andrew MacDonald and Guillaume Blanchet and Vincent Tolon\"\ndate: \"2023-02-10\"\nexecute:\n  echo: true\nformat: \n  revealjs:\n    theme: [default]\n    logo: ../img/UdeS_logo_h_rgbHR.png\n    transition: slide\n    background-transition: fade\n---\n\n\n## \"Complex\" hierarchical model\n\nBy \"complex\" we refer to hierarchical models for which more than one parameters are accounted for in a parameter hierarchy. \n\nAs we will see, there are a number of ways this can complexify the structure of a model in ways that are not always obvious.\n\nBefore we do this, let's get back to the general formation of hierarchical models.\n\n## The general formulation\n\n$$(\\mathbf{y}|\\mathbf{X},\\mathbf{Z}, \\boldsymbol{\\beta}, \\mathbf{b}, \\sigma_\\mathbf{y}^2)\\sim \\mathcal{MVN}(\\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{Z}\\mathbf{b}, \\sigma_\\mathbf{y}^2\\mathbf{I})$$\n\n:::{style=\"font-size: 0.68em\"}\n\nwhere\n\n- $\\mathbf{y}$ is a vector quantifying a response variable of length $n$\n- $\\mathbf{X}$ is a matrix of explanatory variables with $n$ rows (samples) and $p$ columns (explanatory variables) \n- $\\boldsymbol{\\beta}$ is a vector $p$ pararameters weighting the importance of each explanatory variables in $\\mathbf{X}$\n- $\\sigma_\\mathbf{y}^2$ is a measure of variance of the error in the regression model\n- $\\mathbf{I}$ is an $n \\times n$ identity matrix \n\n- $\\mathbf{Z}$ is another matrix of explanatory variables with $n$ rows (samples) and $q$ columns (explanatory variables) \n- $\\mathbf{b}$ is a vector $q$ pararameters weighting the importance of each explanatory variables in $\\mathbf{Z}$\n:::\n\n# \"Complex\" hierarchy on the intercept\n\nICI\nICI\nICI\nICI\n\n## `y ~ (1 | f/g)`\n\n::: {style=\"font-size: 0.7em\"}\nOther notation used : `(1 | f) + (1 | f:g)`\n\nThis model assumes there is a hierarchy that varies among the levels of factor `f` and among the levels of factor `g` but only within the levels of factor `f`.\n\nMathematically, it can be translated to \n\n$$\\mathbf{y} \\sim \\mathcal{MVN}(\\mathbf{b}_{f[l_f]} + \\mathbf{b}_{g[l_g]\\in f[l_f]},\\sigma^2\\mathbf{I}) \\quad\\forall\\quad l_f = 1\\dots k_f\\,\\,\\,\\,\\text{and}\\,\\,\\,l_g = 1\\dots k_g$$\nor \n\n$$y_i = b_{f[l_f]} + b_{g[l_g]\\in f[l_f]} + \\varepsilon \\quad\\forall\\quad l_f = 1\\dots k_f\\,\\,\\,\\,,\\,\\,\\,l_g = 1\\dots k_g\\,\\,\\,\\,\\text{and}\\,\\,\\,i = 1\\dots n$$\nIn words, this means that the model values $b$ will change for a sample $i$ only when the level $l_f$ of the factor $f$ changes or when the level $l_g$ of the factor $g$ **within** the level $l_f$ of the factor $f$ changes. \n\nThis is because in this model\n\n$$\\mathbf{b} \\sim \\mathcal{N}\\left(0, \\begin{bmatrix}\n                                  \\sigma^2_f & 0\\\\\n                                  0& \\sigma^2_{g\\in f}\\\\\n                                \\end{bmatrix}\n                                \\right)$$\n\n:::\n\n\n## `y ~ (1 | f/g)`\n### Stan code for this model\n\n::: {style=\"margin-top: 200px; font-size: 2.5em; color: red;\"}\nFor Andrew?\n:::\n\n## `y ~ (1 | f/g)`\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## `y ~ (1 | f) + (1 | g)`\n\n::: {style=\"font-size: 0.7em\"}\nOther notation used : `y ~ 1 + (1 | f) + (1 | g)`\n\nThis model assumes there is a hierarchy that varies among the two factors.\n\nMathematically, it can be translated to \n\n$$\\mathbf{y} \\sim \\mathcal{MVN}(\\mathbf{b}_{f[l_f]\\times g[l_g]},\\sigma^2\\mathbf{I}) \\quad\\forall\\quad l_f = 1\\dots k_f\\,\\,\\,\\,\\text{and}\\,\\,\\,l_g = 1\\dots k_g$$\nor \n\n$$y_i = b_{f_i[l_f]\\times g_i[l_g]} + \\varepsilon \\quad\\forall\\quad l_f = 1\\dots k_f\\,\\,\\,\\,,\\,\\,\\,l_g = 1\\dots k_g\\,\\,\\,\\,\\text{and}\\,\\,\\,i = 1\\dots n$$\nIn words, this means that the model values $b$ will change for a sample $i$ only when the interaction the level $l_f$ of the factor $f$ and the  level $l_g$ of the factor $g$ changes. \n\nThis is because in this model\n\n$$\\mathbf{b} \\sim \\mathcal{N}\\left(0, \n                                \\begin{bmatrix}\n                                  \\sigma^2_f & \\sigma_f\\sigma_g\\\\\n                                  \\sigma_f\\sigma_g& \\sigma^2_g\\\\\n                                \\end{bmatrix}\n                                \\right)$$\n:::\n\n## `y ~ (1 | f) + (1 | g)`\n\nThis model has a number interesting properties\n\n- It does **not** assumes that the two factors act independent. Actually, if you are interested in such a model, the code to use is not as straight forward to write with these packages.\n- If a particular levels is associated to the same samples for the two factors, usually this create technical problems and the model cannot be estimated properly (this is true regardless of how you estimate these parameter)\n- This can be generalized to as many factors as we want. We will see how this can be useful later.\n\n\n## `y ~ x + (x || g)`\n\n## second\n\n::: r-fit-text\nTest your model\n:::\n\n## \n\nimg:\n\n![](img/bg.jpg)\n\nit is a landscape\n\n##  {auto-animate=\"true\"}\n\n::: {style=\"margin-top: 100px;\"}\ncheck with simulations\n:::\n\n##  {auto-animate=\"true\"}\n\n::: {style=\"margin-top: 200px; font-size: 2.5em; color: red;\"}\ncheck with simulations\n:::\n\n## choose parameters {auto-animate=\"TRUE\"}\n\n``` r\nyintercept <- 4\nslope <- 1.3\nobs_error <- .5\n```\n\n## make up an X variable {auto-animate=\"TRUE\"}\n\n``` r\nyintercept <- 4\nslope <- 1.3\nobs_error <- .5\nx <- runif(200, min = -1, max = 1)\n```\n\n## calculate the average {auto-animate=\"TRUE\"}\n\n``` r\nyintercept <- 4\nslope <- 1.3\nobs_error <- .5\nx <- runif(200, min = -1, max = 1)\ny_mean <- yintercept + slope * x\n```\n\n## simulate some observations {auto-animate=\"TRUE\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyintercept <- 4\nslope <- 1.3\nobs_error <- .5\nx <- runif(200, min = -1, max = 1)\ny_mean <- yintercept + slope * x\ny_obs <- rnorm(200, mean = y_mean, sd = obs_error)\n```\n:::\n\n\n## finally, visualize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y_obs ~ x)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## here it is all on one slide\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nyintercept <- 4\nslope <- 1.3\nobs_error <- .5\nx <- runif(200, min = -1, max = 1)\ny_mean <- yintercept + slope * x\ny_obs <- rnorm(200, mean = y_mean, sd = obs_error)\nplot(y_obs, x)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n## Or we can present the code and results separately\n\n::: panel-tabset\n### The code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyintercept <- 4\nslope <- 1.3\nobs_error <- .5\nx <- runif(200, min = -1, max = 1)\ny_mean <- yintercept + slope * x\ny_obs <- rnorm(200, mean = y_mean, sd = obs_error)\n```\n:::\n\n\n### The figure\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(y_obs ~ x)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n:::\n\n## another equation\n\n$$\n2 + 4 = 6\n$$\n\n## The equation\n\n$$\n\\begin{align}\ny  &\\sim \\text{N}(\\mu, \\sigma_{obs}) \\\\\n\\mu &= a + bx \\\\\n\\end{align}\n$$\n\n## The model {auto-animate=\"TRUE\"}\n\n``` stan\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  mu ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n```\n\n## Declare the data {auto-animate=\"TRUE\"}\n\n``` {.stan code-line-numbers=\"1-4\"}\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  mu ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n```\n\n## State parameters {auto-animate=\"TRUE\"}\n\n``` {.stan code-line-numbers=\"5-8\"}\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  mu ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n```\n\n## Write the likelihood and priors {auto-animate=\"TRUE\"}\n\n``` {.stan code-line-numbers=\"9-13\"}\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  mu ~ normal(0, 1);\n  sigma ~ exponential(1);\n}\n```\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}