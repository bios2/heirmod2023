{
  "hash": "79385019c2d4de192647069e9db387d0",
  "result": {
    "markdown": "---\ntitle: \"Data simulation\"\ndescription: |\n  Expressing yourself through made-up numbers.\nexecute:\n  freeze: true\ncomments:\n  hypothesis: true\nformat:\n  html:\n    code-tools: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cmdstanr)\n```\n:::\n\n\n\nBefore starting work on real data, we are going to begin by learning how to make up some of our own.\nThere are at least three reasons why this is a good idea:\n\n1.  **Understand your priors.**. For most interesting models in ecology, you will not be able to pick good numbers for your prior parameters just by thinking hard. Should the prior on annual tree growth be $\\text{Normal}(2, 1)$ ? or should the standard deviation be bigger? smaller? As we'll see, simulation will demystify the process. \n1. **Validate your model.** Bayesian models are great because they can create datasets by simulation. This suggests a very minimum requirement we might have for a statistical model: use known parameters and a model to generate data, then fit that same model to the very data it generated, and see if we get back something close to those known parameter values.\n1. **Test your understanding.** Perhaps most importantly, simulation helps you to test your own intuition.  If you can simulate data from your model, then you really understand it!\nIf you can't, then you don't know quite how it works yet. It's rare^[in Andrew's experience anyway] that a biologist will fail to learn something by simulating a dataset.\n\n## Simple exercise in simulation\n\nLet's imagine we are taking a walk as a group today at the beautiful SBL. What is the number of birds each of us is going to see on our hike?\n\n### Some questions to ask about simulated data\n\n1. What kind of observations are you going to make? Do they have a minimum or maximum value?\nAre they integers, or are they decimal numbers, or something else?\n1. Where do the numbers come from? This could be anything, from simple linear approximations (ie the models we're looking at in this course) to ODEs, mathematical models, GAMs, etc. \n1. How many observations will we be making?\n\n### The process\n\nlet's try to answer these questions for the bird walk we are about to take.\n\n1. We're going to count birds, so we'll have count data: a number that is either 0 or some positive, round number\n2. We'll make a simplifying assumption: everybody has the same chance of seeing a bird (i.e. no differences in skill or equipment), and everyone in the class is an independent observer (i.e. nobody is working in pairs, etc) \n3. Everyone in the class makes only one count, so we have 23 (?) numbers.\n\nWe're bayesians, so we need to write a probability distribution for all the possible values\n\n$$\n\\begin{align}\n\\text{Number of Birds}_{\\text{seen by person i}} &\\sim \\text{Poisson}(\\lambda) \\\\\n\\lambda &\\sim \\text{Uniform}(0, 60)\n\\end{align}\n$$\n\nA quick note about notation for models like these:\n\n* We use a subscript $i$ to indicate the \"label\" for each observation in our dataset. You can think of this as the row number of the data spreadsheet, and imagine sliding your finger down the column of measurements, modelling each value in turn.\n* Usually we'll use more general language, such as $y_i$. But for this simple example I wanted to make things as explicit as possible. \n* Notice the symbol $\\sim$. This is read as \"distributed as\", and indicates the probability distribution from which the values might come.  When the values we're talking about are data that we can observe (in this case, counts of birds), we call the distribution the likelihood. When the value is something we can't observe (in this case, the average count $\\lambda$) we call the distribution the prior.\n\n::: {.callout-warning}\nWe'll be talking about better ways to model count data in a later exercise! For now, I'm using the Uniform distribution for simplicity. It's not usually a very good choice! \n:::\n\n### Simulation in R\n\nOne of the most useful traits of bayesian models is that they are _generative_: they can be used to make a simulated dataset. \nWe'll do that now for our bird example.\n\nlet's simulate from a poisson distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(525600)\nn_people <- 21\navg_birds_per_person <- runif(1, min = 0, max = 30)\nbird_count <- rpois(n_people, lambda = avg_birds_per_person)\n```\n:::\n\n\nSome things to note in the code above: \n\nEvery statistical distribution that is in R (which is a lot! almost all! ) has four different functions. \nIf the distribution is called `dist`, then they are:\n\n* `rdist` = the distribution functions \n* `qdist` = the quantile functions \n* `pdist` = the probability density function \n* `ddist` the density function\n\nThe other thing to note is that there are TWO simulation steps here: first, simulating a value of the average ($\\lambda$) and second, simulating observations. \nIn our model, the Uniform distribution was referred to as the _prior_, and the Poisson distribution was referred to as a _likelihood_, but here you can see that they are very nearly the same thing: just statements about what distribution of values might be most consistent with the data.\n\n#### Plotting the result\n\nLet's take a look at our simulated values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(bird_count, col = \"lightblue\", xlim = c(0, 50))\n```\n\n::: {.cell-output-display}\n![Histogram of simulated counts of birds](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis is pretty great, and represents one possible realization of sampling. \nHowever, one sample isn't enough to tell us about what our $\\text{Uniform}(0, 60)$ prior really means. Let's do a few different simulations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nset.seed(525600)\n\nsimulate_some_birds <- function() {\n  lambda <- runif(1, min = 0, max = 60)\n  data.frame(obs = rpois(23, lambda = lambda))\n}\n  \npurrr::rerun(.n = 12, simulate_some_birds()) |> \n  dplyr::bind_rows(.id = \"sample\") |> \n  ggplot(aes(x = obs)) + \n  geom_histogram() + \n  facet_wrap(~sample) + \n  theme_bw() + \n  labs(x = \"Number of birds observed per person\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![Twelve different simulations of a possible bird dataset. Do all of these seem plausible?](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThis figure shows different simulations of what, according to our prior, might be reasonable datasets for us to study. Do any of them seem implausible to you? If so, try changing the prior. The goal is to make fake datasets that _seem_ plausible, but which still include the possibility of some surprising observations. \n\nWhen you have a prior that generates observations that cover a range of scientifically reasonable values, then you are ready to move on to fitting real data.\n\nHowever before we actually do that, let's do the whole thing again: this time in Stan.\n\n## Simulating data in Stan\n\nLet's look back at the equation:\n\n$$\n\\begin{align}\n\\text{Number of Birds}_{\\text{seen by person i}} &\\sim \\text{Poisson}(\\lambda) \\\\\n\\lambda &\\sim \\text{Uniform}(0, 60)\n\\end{align}\n$$\n\nAnd then translate it into Stan:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoisson_simulation <- cmdstan_model(\n  stan_file = \"topics/01_simulation/poisson_simulation.stan\")\n\npoisson_simulation\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> n_people;\n}\ngenerated quantities {\n  real<lower=0> avg_birds_per_person;\n  // an array -- like a list in R\n  array[n_people] int<lower=0> bird_count;\n  \n  // simulate averages\n  avg_birds_per_person = uniform_rng(0, 60);\n  // simulate observations with that average\n  for (i in 1:n_people){\n    bird_count[i] = poisson_rng(avg_birds_per_person);\n  }\n}\n```\n:::\n:::\n\n\nWhat you see just above is not R, but is the first Stan program we will see in this course. \nStan code is written in a text file, which you then bring into R with the function `cmdstan_model` as shown above. \nThis does more than read the program, it compiles the code into a computer program. \nWhen you sample the model, as we'll do later, Stan samples the posterior distribution using Hamiltonian Monte Carlo.\n\nThis Stan program has two parts. Each part is separated with curly braces `{}`. The are they `data` block and the `generated quantities` block:\n\n```stan\ndata {\n  int<lower=0> n_people;\n}\n```\n\nAnd the generated quantites block.\n\n```stan\ngenerated quantities {\n  real<lower=0> avg_observed;\n  // an array -- like a list in R\n  array[n_people] int<lower=0> bird_count;\n  \n  // simulate averages\n  avg_birds_per_person = uniform_rng(0, 60);\n  // simulate observations with that average\n  for (i in 1:n_people){\n    bird_count[i] = poisson_rng(avg_birds_per_person);\n  }\n}\n```\n\n```\n\nLet's look at similarities and differences to the procedure in R:\n\nsimilarities: \n\n* We have a random number generating function for each of our distributions. \nIn R, these were called `runif` and `rpois`, here they are `uniform_rng` and `poisson_rng`.\n* Once again, the only thing we need to provide is `n_people`, the number of observers we have\n\ndifferences:\n\n* every line ends with a semicolon `;`\n* in Stan, the name of a variable is on the RIGHT of a line, while in R it's on the left.\n* we need to use a for-loop to generate random variables.\n* note the syntax for creating an `array` of integers. Arrays in Stan are a little like lists in R: they can hold any other kind of object, and are of a certain length. \n\n::: {.cell}\n\n```{.r .cell-code}\npoisson_sim_stan <- poisson_simulation$sample(data = list(n_people = 21), \n                          # usually not necessary -- this model has no parameters \n                          fixed_param = TRUE\n                          )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 1 Iteration: 100 / 1000 [ 10%]  (Sampling) \nChain 1 Iteration: 200 / 1000 [ 20%]  (Sampling) \nChain 1 Iteration: 300 / 1000 [ 30%]  (Sampling) \nChain 1 Iteration: 400 / 1000 [ 40%]  (Sampling) \nChain 1 Iteration: 500 / 1000 [ 50%]  (Sampling) \nChain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 2 Iteration: 100 / 1000 [ 10%]  (Sampling) \nChain 2 Iteration: 200 / 1000 [ 20%]  (Sampling) \nChain 2 Iteration: 300 / 1000 [ 30%]  (Sampling) \nChain 2 Iteration: 400 / 1000 [ 40%]  (Sampling) \nChain 2 Iteration: 500 / 1000 [ 50%]  (Sampling) \nChain 2 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 2 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 2 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 2 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 2 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 3 Iteration: 100 / 1000 [ 10%]  (Sampling) \nChain 3 Iteration: 200 / 1000 [ 20%]  (Sampling) \nChain 3 Iteration: 300 / 1000 [ 30%]  (Sampling) \nChain 3 Iteration: 400 / 1000 [ 40%]  (Sampling) \nChain 3 Iteration: 500 / 1000 [ 50%]  (Sampling) \nChain 3 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 3 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 3 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 3 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 3 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:   1 / 1000 [  0%]  (Sampling) \nChain 4 Iteration: 100 / 1000 [ 10%]  (Sampling) \nChain 4 Iteration: 200 / 1000 [ 20%]  (Sampling) \nChain 4 Iteration: 300 / 1000 [ 30%]  (Sampling) \nChain 4 Iteration: 400 / 1000 [ 40%]  (Sampling) \nChain 4 Iteration: 500 / 1000 [ 50%]  (Sampling) \nChain 4 Iteration: 600 / 1000 [ 60%]  (Sampling) \nChain 4 Iteration: 700 / 1000 [ 70%]  (Sampling) \nChain 4 Iteration: 800 / 1000 [ 80%]  (Sampling) \nChain 4 Iteration: 900 / 1000 [ 90%]  (Sampling) \nChain 4 Iteration: 1000 / 1000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.7 seconds.\n```\n:::\n:::\n\nThis generates a large number of simulated datasets -- the default is 4000 datasets! \nEach time the model samples, it draws a new value for the unobserved average (`avg_birds_per_person`) and for the number of birds seen by each person. \n\nLet's pull out just a few of these datasets and visualize them.\n\nWe'll use a wonderful package called [`tidybayes`]() to easily extract posterior draws from `cmdstan` objects. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidybayes)\npois_sim <- tidybayes::spread_draws(poisson_sim_stan, \n                                    avg_birds_per_person,\n                                    bird_count[],\n                                    ndraws = 20,\n                                    seed = 525600)\n\npois_sim |> \n  ggplot(aes(x = bird_count)) + \n  geom_histogram() + \n  geom_vline(aes(xintercept = avg_birds_per_person), col = \"darkgreen\") + \n  facet_wrap(~.draw)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n## Parameter recovery\n\nLet's go back and look at the fake datasets we created in R \n\n\n::: {.cell}\n\n```{.r .cell-code}\navg_birds_per_person\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 17.12789\n```\n:::\n\n```{.r .cell-code}\nbird_count\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 23 10 19 27 20 15 16 18 18 22 14 14 14 18 17 13 26 19 16 13 10\n```\n:::\n:::\n\n\nand let's see if we can recapture these parameters.\n\nWe'll do it first in R, using the function `fitdistr` from the `MASS` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMASS::fitdistr(bird_count, dpois, start = list(lambda=10))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in stats::optim(x = c(23L, 10L, 19L, 27L, 20L, 15L, 16L, 18L, 18L, : one-dimensional optimization by Nelder-Mead is unreliable:\nuse \"Brent\" or optimize() directly\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n     lambda  \n  17.2382812 \n ( 0.9060239)\n```\n:::\n:::\n\n\nThis could also be done with `glm`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbird_glm <- glm(bird_count ~ 1, family = \"poisson\")\nexp(coef(bird_glm))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept) \n    17.2381 \n```\n:::\n:::\n\n\nYou can see that in all cases we are getting close to the value of `avg_birds_per_person`, which in these simulations is the true value.\n\n### Sampling the posterior distribution in Stan\n\nWe will be doing a lot of Stan models this week, and we will begin by replicating the above GLM in Stan.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoisson_model <- cmdstan_model(\n  stan_file = \"topics/01_simulation/poisson_model.stan\")\n\npoisson_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> n_people;\n  array[n_people] int<lower=0> bird_count_observed;\n}\nparameters {\n  real avg_birds_per_person;\n}\nmodel {\n  bird_count_observed ~ poisson(avg_birds_per_person);\n  avg_birds_per_person ~ normal(1, 1);\n}\ngenerated quantities {\n  // an array -- like a list in R\n  array[n_people] int<lower=0> bird_count;\n  \n  // simulate observations with that average\n  for (i in 1:n_people){\n    bird_count[i] = poisson_rng(avg_birds_per_person);\n  }\n}\n```\n:::\n:::\n\n\nThis model has all the same code as the previous one, but has two additional parts. \nLet's compare them\n\n:::{.column-screen}\n\n::::{.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-wrap}\npoisson_simulation\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> n_people;\n}\ngenerated quantities {\n  real<lower=0> avg_birds_per_person;\n  // an array -- like a list in R\n  array[n_people] int<lower=0> bird_count;\n  \n  // simulate averages\n  avg_birds_per_person = uniform_rng(0, 60);\n  // simulate observations with that average\n  for (i in 1:n_people){\n    bird_count[i] = poisson_rng(avg_birds_per_person);\n  }\n}\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-wrap}\npoisson_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> n_people;\n  array[n_people] int<lower=0> bird_count_observed;\n}\nparameters {\n  real avg_birds_per_person;\n}\nmodel {\n  bird_count_observed ~ poisson(avg_birds_per_person);\n  avg_birds_per_person ~ normal(1, 1);\n}\ngenerated quantities {\n  // an array -- like a list in R\n  array[n_people] int<lower=0> bird_count;\n  \n  // simulate observations with that average\n  for (i in 1:n_people){\n    bird_count[i] = poisson_rng(avg_birds_per_person);\n  }\n}\n```\n:::\n:::\n\n:::\n\n::::\n\n:::\n\nWhat's different in this second Stan program\n\n* parameters block\n* model block\n* the average is now moved to the model, no longer in the generated quantities\n\n## Prior vs Posterior predictive checks\n\n## Parameter recovery\n\nThen we look to see if we have recovered our parameter.\n\n\n## Bonus material: conjugacy\n\nYou would never actually do the analysis on this page. In reality, for simple distributions such as the Poisson, we would \n\n## Exercises\n\n* ",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}