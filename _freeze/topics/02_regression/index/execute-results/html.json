{
  "hash": "658348051188d2b1f66b392074442815",
  "result": {
    "markdown": "---\ntitle: \"Univariate regression\"\ndescription: |\n  The shortest route to science is a straight line.\nexecute:\n  freeze: true\ncomments:\n  hypothesis: true\nformat:\n  html:\n    code-tools: true\n---\n\n\n[Notes for today](https://docs.google.com/document/d/1XhJIuKhLI-xG4rySntHgrps0PVQOZDt1bsJor7INY5c/edit?usp=sharing)\n\n## Return to Simpson's Paradox\n\nWe'll return to the Palmer penguins, and look at Simpson's paradox in Stan.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(palmerpenguins)\nlibrary(tidyverse)\nlibrary(cmdstanr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is cmdstanr version 0.5.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStan path: /Users/amacdonald/.cmdstan/cmdstan-2.31.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStan version: 2.31.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidybayes)\npenguins |> \n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point() + \n  stat_smooth(method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nLet's write a simple statistical model for these data:\n\n$$\n\\begin{align}\n\\text{Bill depth}_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\beta_0 + \\beta_1\\times\\text{Bill length}_i \\\\\n\\beta_0 &\\sim \\text{Normal}(??) \\\\\n\\beta_1 &\\sim \\text{Normal}(??) \\\\\n\\sigma &\\sim \\text{Exponential}(??)\n\\end{align}\n$$\n\nWhat should our priors be? Before we can answer that, we have a more important question:\n\n:::{.callout-warning}\n# WHERE IS ZERO??\nIt has to be somewhere. Does it make sense? take control and choose for yourself.\n:::\n\nIf we fit a model like this **without** thinking about the location of zero, we get some pretty silly answers:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbill_line <- coef(lm(bill_depth_mm ~ bill_length_mm, data = penguins))\n```\n:::\n\n\nWhen the value of bill length is 0, the average of the response is the intercept:\n\n$$\n\\begin{align}\n\\mu_i &= \\beta_0 + \\beta_1\\times\\text{Bill length}_i \\\\\n\\mu_i &= \\beta_0 + \\beta_1\\times0 \\\\\n\\mu_i &= \\beta_0 \\\\\n\\end{align}\n$$\n\nBut, if we take the data as we found it, we're going to be talking about $\\beta_0$ as the depth of a penguin's bill _when the bill has 0 length!_ Either way it is the same line. However, from the point of view of setting priors and interpreting coefficients, it helps a lot to set a meaningful 0.\n\nA very common choice is to **subtract the average** from your independent variable, so that it is equal to 0 at the average:\n\n$$\n\\begin{align}\n\\text{Bill depth}_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\beta_0 + \\beta_1\\times(\\text{Bill length}_i  - \\overline{\\text{Bill length}})\\\\\n\\beta_0 &\\sim \\text{Normal}(??) \\\\\n\\beta_1 &\\sim \\text{Normal}(??)\n\\end{align}\n$$\n\nNow $\\beta_0$ means the average _bill depth_ at the average _bill length_.  It becomes easier to think about priors:\n\n$$\n\\begin{align}\n\\text{Bill depth}_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\beta_0 + \\beta_1\\times(\\text{Bill length}_i  - \\overline{\\text{Bill length}})\\\\\n\\beta_0 &\\sim \\text{Normal}(17,2) \\\\\n\\beta_1 &\\sim \\text{Normal}(0,.5) \\\\\n\\sigma &\\sim \\text{Exponential}(0.5)\n\\end{align}\n$$\n\n:::{.callout-note}\n## Exercise\n\nWhat continuous predictors have you used in your analysis? How would you find a biologically meaningful zero? Think about how you would center time, age, mass, fitness etc.\n:::\n\n## Prior predictive simulations\n\nArmed with this model, it becomes much easier to think about prior predictions.\n\nWe'll make a bunch of lines implied by the equation above. There's two steps:\n\n1. Center the predictor\n2. Make up a vector that goes from the minimum to the maximum of the predictor. This is just for convenience!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbill_len_centered <- with(penguins,\n                          bill_length_mm - mean(bill_length_mm,\n                                                na.rm = TRUE))\n\n## make up a short vector\nsome_bill_lengths <- seq(\n  from = min(bill_len_centered, na.rm = TRUE), \n  to = max(bill_len_centered, na.rm = TRUE),\n  length.out = 10\n  )\n```\n:::\n\n\n:::{.callout-warning}\n## Shortcuts to these common tasks\n\nThese tasks are so common that they are automated in helper functions.\n\nFor centering predictors, see the base R function `?scale`\n\nFor creating a short vector over the range of a predictor, see `modelr::seq_range`. The R package [`modelr`](https://modelr.tidyverse.org/) has many different functions to help with modelling.\n:::\n\nTo simulate, we'll use some matrix algebra, as we saw in lecture:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nslopes <- rnorm(7, 0, .5)\ninters <- rnorm(7, 17, 2)\n\nX <- cbind(1, some_bill_lengths)\nB <- rbind(inters, slopes)\n\nprior_mus <- X %*% B\n\nmatplot(x = some_bill_lengths,\n        y = prior_mus, type = \"l\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n:::{.callout-note}\n## Exercise\n\nCopy the code above. Increase the number of simulations. Which priors are too wide? Which are too narrow?\n:::\n\n### Simulating Observations\n\nThere are always at least TWO kinds of predictions we can be thinking about: \n\n1. Predicted averages\n2. Predicted observations\n\nWe can use the full model to simulate observations! \n\n\n::: {.cell}\n\n```{.r .cell-code}\nslopes <- rnorm(7, 0, .5)\ninters <- rnorm(7, 17, 2)\nsigmas <- rexp(7, rate = 0.3)\n\nX <- cbind(1, some_bill_lengths)\nB <- rbind(inters, slopes)\n\nprior_mus <- X %*% B\n\nprior_obs <- matrix(0, nrow = nrow(prior_mus), ncol = ncol(prior_mus))\n\nfor (j in 1:ncol(prior_obs)) {\n  prior_obs[,j] <- rnorm(n = nrow(prior_mus),\n                         mean = prior_mus[,j],\n                         sd = sigmas[j])\n}\n\nmatplot(x = some_bill_lengths,\n        y = prior_obs, type = \"p\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nTidyverse style for those who indulge:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  sim_id = 1:7,\n  slopes = rnorm(7, 0, .5),\n  inters = rnorm(7, 17, 2),\n  sigmas = rexp(7, rate = 0.4)\n  ) |> \n  mutate(x = list(seq(from = -10, to = 10, length.out = 6))) |> \n  rowwise() |> \n  mutate(avg = list(x * slopes + inters),\n         obs = list(rnorm(length(avg), mean = avg, sd = sigmas))) |> \n  unnest(cols = c(\"x\", \"avg\", \"obs\")) |> \n  ggplot(aes(x= x, y = avg, group = sim_id, colour = sim_id)) + \n  geom_line() + \n  geom_point(aes(y = obs)) + \n  scale_color_distiller(type = \"qual\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using a discrete colour palette in a continuous scale\nâ„¹ Consider using `type = \"seq\"` or `type = \"div\"` instead\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n## Linear regression in Stan\n\nNow we write a Stan program for this model. \nWe'll begin with a simple model that has no posterior predictions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal_regression_no_prediction <- cmdstan_model(\n  stan_file = \"topics/02_regression/normal_regression_no_prediction.stan\")\n\nnormal_regression_no_prediction\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> N;\n  vector[N] bill_len;\n  vector[N] bill_dep;\n}\nparameters {\n  real intercept;\n  real slope;\n  real<lower=0> sigma;\n}\nmodel {\n  bill_dep ~ normal(intercept + slope * bill_len, sigma);\n  intercept ~ normal(17, 2);\n  slope ~ normal(0, 1);\n  sigma ~ exponential(.7);\n}\n```\n:::\n:::\n\n\nIn order to get the posterior, we need to put our data in Stan. Remember to remove NAs first! \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## drop NAs\npenguins_no_NA <- penguins |> \n  tidyr::drop_na(bill_depth_mm, bill_length_mm) |> \n  dplyr::mutate(\n    bill_length_center = bill_length_mm - mean(bill_length_mm))\n\n## assemble data list\ndata_list <- with(penguins_no_NA,\n     list(N = length(bill_length_center),\n          bill_len = bill_length_center,\n          bill_dep = bill_depth_mm\n          ))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal_reg_no_pred <- normal_regression_no_prediction$sample(\n  data = data_list, \n  refresh = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 2 Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in '/var/folders/x7/l08zn2396g797m5ws54np_6w0000gp/T/Rtmpw7jYom/model-daed2bca650f.stan', line 12, column 2 to column 57)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nChain 2 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nChain 2 finished in 0.2 seconds.\nChain 3 finished in 0.2 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 1.2 seconds.\n```\n:::\n\n```{.r .cell-code}\nnormal_reg_no_pred$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 Ã— 10\n  variable       mean    median     sd    mad       q5       q95  rhat ess_bulk\n  <chr>         <num>     <num>  <num>  <num>    <num>     <num> <num>    <num>\n1 lp__      -396.     -395.     1.24   0.953  -398.    -394.      1.00    2113.\n2 intercept   17.2      17.1    0.101  0.0981   17.0     17.3     1.00    4041.\n3 slope       -0.0851   -0.0852 0.0187 0.0182   -0.116   -0.0541  1.00    3957.\n4 sigma        1.92      1.92   0.0743 0.0733    1.80     2.05    1.00    3720.\n# â„¹ 1 more variable: ess_tail <num>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal_reg_no_pred$draws() |> \n  bayesplot::mcmc_areas(pars = c(\"slope\", \"intercept\", \"sigma\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Posterior predictions in Stan\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormal_regression <- cmdstan_model(stan_file = \"topics/02_regression/normal_regression.stan\")\n\nnormal_regression\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> N;\n  vector[N] bill_len;\n  vector[N] bill_dep;\n  // posterior predictions\n  int<lower=0> npost;\n  vector[npost] pred_values;\n}\nparameters {\n  real intercept;\n  real slope;\n  real<lower=0> sigma;\n}\nmodel {\n  bill_dep ~ normal(intercept + slope * bill_len, sigma);\n  intercept ~ normal(17, 2);\n  slope ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[npost] post_bill_dep_obs;\n  vector[npost] post_bill_dep_average;\n  \n  // calculate expectation\n  post_bill_dep_average = intercept + slope * pred_values;\n  \n  // make fake observations\n  for (i in 1:npost) {\n    post_bill_dep_obs[i] = normal_rng(intercept + slope * pred_values[i], sigma);\n  }  \n  \n}\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_no_NA <- penguins |> \n  tidyr::drop_na(bill_depth_mm, bill_length_mm) |> \n  dplyr::mutate(\n    bill_length_center = bill_length_mm - mean(bill_length_mm))\n\ndata_list <- with(penguins_no_NA,\n     list(N = length(bill_length_center),\n          bill_len = bill_length_center,\n          bill_dep = bill_depth_mm,\n          npost = 6,\n          pred_values = modelr::seq_range(penguins_no_NA$bill_length_center, n = 6)\n          ))\n\nbill_norm_reg <- normal_regression$sample(data = data_list, \n                                          refresh = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 1.0 seconds.\n```\n:::\n:::\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nbill_posterior <- bill_norm_reg |> \n  tidybayes::spread_rvars(post_bill_dep_average[i],\n                          post_bill_dep_obs[i]) |>\n  mutate(bill_length = data_list$pred_values[i]) \n\nbill_posterior |> \n  ggplot(aes(x = bill_length, dist = post_bill_dep_average)) + \n  tidybayes::stat_lineribbon() + \n  geom_point(aes(x = bill_length_center, y = bill_depth_mm),\n             data = penguins_no_NA, \n             inherit.aes = FALSE) + \n  scale_fill_brewer(palette = \"Greens\", direction = -1, guide = \"none\") + \n  labs(title = \"Average response\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using the `size` aesthetic with geom_ribbon was deprecated in ggplot2 3.4.0.\nâ„¹ Please use the `linewidth` aesthetic instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `linewidth`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using the `size` aesthetic with geom_line was deprecated in ggplot2 3.4.0.\nâ„¹ Please use the `linewidth` aesthetic instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbill_posterior |> \n  ggplot(aes(x = bill_length, dist = post_bill_dep_obs)) + \n  tidybayes::stat_lineribbon() + \n  geom_point(aes(x = bill_length_center, y = bill_depth_mm),\n             data = penguins_no_NA, \n             inherit.aes = FALSE) + \n  scale_fill_brewer(palette = \"Greens\", direction = -1, guide = \"none\") +\n  labs(title = \"Predicted observations\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n\n\nNow, what I would like you to do is to extend this model to include species. Specifically, let each species have its own value of the `intercept`.\n\n<!-- don't print this code in the output!-->\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbill_posterior <- normal_reg_spp_post |> \n  tidybayes::spread_rvars(post_bill_dep_average[i],\n                          post_bill_dep_obs[i]) |>\n  mutate(bill_length = data_list_spp$pred_values[i],\n         spp = data_list_spp$pred_spp_id) \n\nbill_posterior |> \n  ggplot(aes(x = bill_length, dist = post_bill_dep_average, group = spp)) + \n  tidybayes::stat_lineribbon() + \n  geom_point(aes(x = bill_length_center, y = bill_depth_mm),\n             data = penguins_no_NA, \n             inherit.aes = FALSE) + \n  scale_fill_brewer(palette = \"Greens\", direction = -1, guide = \"none\") + \n  labs(title = \"Average response\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\nUnknown or uninitialised column: `linewidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbill_posterior |> \n  ggplot(aes(x = bill_length, dist = post_bill_dep_obs)) + \n  tidybayes::stat_lineribbon() + \n  geom_point(aes(x = bill_length_center, y = bill_depth_mm),\n             data = penguins_no_NA, \n             inherit.aes = FALSE) + \n  scale_fill_brewer(palette = \"Greens\", direction = -1, guide = \"none\") +\n  labs(title = \"Predicted observations\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Computation failed in `stat_lineribbon()`\nCaused by error:\n! 3 distributions in `dist` were associated with the same\ncombination of other aesthetics.\n- Distributions passed to the `dist` aesthetic must be uniquely associated\n  with a combination of levels of the `group` and some other aesthethics\n  (like x, y, color, fill, etc) so that unique intervals, densities, etc.\n  of those distributions are well defined.\n- Try checking whether you need to adjust the `group` aesthetic or provide\n  some other aesthetic mapping (like color or fill) to differentiate\n  distributions.\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n:::\n\n\n## Exercise! \n\nshow how the $\\sigma$ is different between these two models\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}