{
  "hash": "8c81a58afa04d84d18e2b3f9a24191a1",
  "result": {
    "markdown": "---\ntitle: Day 1\ndescription: |\n  General Introduction, introduction to simulation, model checking, and Stan workflows.\nimage: assets/plot_resampModel-1.png\nexecute:\n  freeze: auto\nformat:\n  html:\n    code-tools: true\n---\n\n\n## Slides from the day\n\n### Introduction\n\n\n<div>\n\n\n```{=html}\n<iframe width=100% height=500pxaside class=\"slide-deck\" src=\"slides/Introduction/\"></iframe>\n```\n\n\n</div>\n\n\n### Template\n\n\n<div>\n\n\n```{=html}\n<iframe width=100% height=500pxaside class=\"slide-deck\" src=\"slides/template/\"></iframe>\n```\n\n\n</div>\n\n## Content\n\n[The Secret Weapon](topics/secret_weapon.qmd)\n\n[regression with discrete predictors](topics/discrete_predictor/index.qmd)\n\n\n\n\n\n\n\n\n\n\n\n### Afternoon practical exercises\n\n## Course setup information\n\n* site information\n* plagiarism\n\n## Simulation\n\n## Quantifying uncertainty\n\n# Worked examples and activities\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(mite,package = \"vegan\")\ndata(mite.env, package = \"vegan\")\nlibrary(tidyverse)\n\nmite_water <- bind_cols(water = mite.env$WatrCont, mite) |> \n  arrange(water) |> \n  pivot_longer(-water, names_to = \"sp\", values_to = \"abd\") |> \n  mutate(pa = as.numeric(abd>.5))\n\nmite_water |> \n  ggplot(aes(x = water, y = pa)) + \n  geom_point() + \n  facet_wrap(~sp) + \n  stat_smooth(method = \"glm\",\n              method.args = list(family = \"binomial\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](day_1_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n## Resampling\n\nIn frequentist models, we can use the variance covariance matrix of parameters to resample new parameters values. This lets us propagate uncertainty from the estimated parameters to the predicted relationship.\n\nLet's demonstrate this with one specific mite:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlrug_water <- mite_water |> \n  filter(sp == \"LRUG\")\n\nlrug_glm <- glm(pa ~ water, data = lrug_water, family = \"binomial\")\n```\n:::\n\n\nNow, with our model object, we can create the resampling distribution of the model predicitons:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed\nset.seed(42) # The answer !\n\n# a sequence along the range of water values in the data\npredVal <- seq(from = min(lrug_water$water),\n               to = max(lrug_water$water),\n               length.out = 30)\n\nn_resamp <- 500\n\n# Result object\nresampModel <- array(NA_real_,\n                   dim = c(length(predVal), n_resamp))\n\n# Resample model parameters and calculate model predictions\nparamMean <- summary(lrug_glm)$coefficients[,1]\nparamCov <- summary(lrug_glm)$cov.unscaled\n\n# Resample model parameters\nparamSmpl <- MASS::mvrnorm(n_resamp, paramMean, paramCov)\n\n# Calculate model predictions using the resampled model parameters\nfor(j in 1:n_resamp){\n  resampModel[,j] <- binomial(link = \"logit\")$linkinv(\n    paramSmpl[j,1] + paramSmpl[j,2] * predVal)\n}\n\n# make a plot of these predictions\nmatplot(predVal, resampModel, type = \"l\", col = \"grey\", lty = 1)\n```\n\n::: {.cell-output-display}\n![](day_1_files/figure-html/resample_model-1.png){width=672}\n:::\n:::\n\n\nIf we want to find some kind of confidence interval for this line, we can take the quantiles of this resampling:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlow <- apply(resampModel, 1, quantile, probs = .015)\nhigh <- apply(resampModel, 1, quantile, probs = .985)\n\n# plot\nwith(lrug_water, plot(pa ~ water, pch = 21, bg = \"lightblue\"))\npolygon(c(predVal,rev(predVal)),\n        c(low,rev(high)), col=\"thistle\", border=NA)\nlines(predVal, \n      predict(lrug_glm, newdata = list(water = predVal), type = \"response\")\n      )\n```\n\n::: {.cell-output-display}\n![](assets/plot_resampModel-1.png){width=672}\n:::\n:::\n\n\nWe can also do this in a tidyverse style, if you are more comfortable with that:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(predVal) |> \n  rowwise() |> \n  mutate(intercept = list(paramSmpl[,1]),\n         slope = list(paramSmpl[,2]),\n         prediction = list(intercept + slope*predVal),\n         prediction_probability = list(plogis(prediction)),\n         low  = quantile(prediction_probability, .015),\n         high = quantile(prediction_probability, .985)) |> \n  ggplot(aes(x = predVal, ymin = low, ymax = high)) + \n  geom_ribbon(fill = \"thistle\") + \n  theme_bw() + \n  ylim(c(0,1))\n```\n\n::: {.cell-output-display}\n![](day_1_files/figure-html/tidyverse_style-1.png){width=672}\n:::\n:::\n\n\n## Bayesian approach\n\nhere is a simple bayesian model to generate the same inference:\n\n$$\n\\begin{align}\ny &\\sim \\text{Bernoulli}(p)\\\\\n\\text{logit}(p) &= \\alpha + X\\beta\\\\\n\\alpha &\\sim \\text{Normal}(-2.5, .5)\\\\\n\\beta &\\sim \\text{Normal}(0, .5)\\\\\n\\end{align}\n$$\n\n[normally we would go through a careful process of checking our priors here. At this time we won't because the point here is to show how the bayesian posterior includes uncertainty, not to demonstrate a full Bayes workflow.]{.aside}\n\nFirst we compile the model, then we'll look at the Stan code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cmdstanr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is cmdstanr version 0.5.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStan path: /Users/blag1404/.cmdstan/cmdstan-2.31.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- CmdStan version: 2.31.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n```\n:::\n\n```{.r .cell-code}\nlogistic_glm_stan <- cmdstan_model(stan_file = \"stan/logistic_bern_logit.stan\", \n                               pedantic = TRUE)\n\nlogistic_glm_stan\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> n;\n  vector[n] x;\n  array[n] int<lower=0,upper=1> y;\n}\nparameters {\n  real intercept;\n  real slope;\n}\nmodel {\n  y ~ bernoulli_logit(intercept + slope * x);\n  intercept ~ normal(-2.5, .5);\n  slope ~ normal(0, .5);\n}\n```\n:::\n:::\n\n\nHere we see the same three parts of a Stan model that we have reviewed already:\n\n-   data\n-   parameters\n-   probability statements\n\nAs you can see, we are using a handy Stan function called `bernoulli_logit`. This function expects our prediction for the average to be on the logit scale, then applies the logit link function for us.\n\n::: column-margin\nAs a quick review, the logit equation, or inverse-log-odds, is written as $$\n\\frac{e^\\mu}{1 + e^\\mu}\n$$ Which is also written as\n\n$$\n\\frac{1}{1 + e^{-\\mu}}\n$$\n:::\n\nStan expects our data as a list.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic_glm_stan_samples <- logistic_glm_stan$sample(\n  data = list(n = nrow(lrug_water),\n              y = lrug_water$pa,\n              x = lrug_water$water),\n  refresh = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 finished in 0.2 seconds.\nChain 4 finished in 0.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 1.0 seconds.\n```\n:::\n\n```{.r .cell-code}\ncoef(lrug_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)       water \n-2.48153943  0.00874349 \n```\n:::\n\n```{.r .cell-code}\nlibrary(tidybayes)\n\nspread_rvars(logistic_glm_stan_samples, intercept, slope[]) |> \n  bind_cols(predVal = predVal) |> \n  mutate(pred = posterior::rfun(plogis)(predVal * slope + intercept)) |> \n  ggplot(aes(x = predVal, ydist = pred)) + \n  stat_dist_lineribbon() + \n  guides(fill = \"none\") + \n  ylim(c(0,1))\n```\n\n::: {.cell-output-display}\n![](day_1_files/figure-html/sample_and_plot-1.png){width=672}\n:::\n:::\n\n\n### Alternative parameterization\n\nStan contains many functions intended to facilitate writing statistical models.\nAbove, we used the function `bernoulli_logit` so that we could provide the expression for the average on the logit scale. [This idea is the core concept of a GLM, or generalized linear model. Statistical distributions have parameters, but for most distributions these have constraints -- only some values are \"allowed\". For example, the only parameter of a Bernoulli distribution is $p$, the probability of success. We respect this constraint by using a link function: we write an expression for the average of a distribution that can be any real number, and put it through a link function to get the value for $p$.]{.aside} Stan also provides an even more efficient function that we can use; it is especially good when we have more than one predictor variable and a vector of slopes:\n\n:::{.callout-warning}\nPLEASE NOTE below you will see the relative path to the stan file (`stan/logistic.stan`).\nImmediately below you will see the Stan file content. \nYou can copy and paste this to your own computer!\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages(library(cmdstanr))\n\nlogistic_bern_glm <- cmdstan_model(stan_file = \"stan/logistic.stan\", \n                               pedantic = TRUE)\n\nlogistic_bern_glm\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.stan}\ndata {\n  int<lower=0> N;\n  matrix[N, 1] x;\n  array[N] int<lower=0,upper=1> y;\n}\nparameters {\n  real intercept;\n  vector[1] slope;\n}\nmodel {\n  intercept ~ normal(-2.5, .5);\n  slope ~ normal(0, .5);\n  y ~ bernoulli_logit_glm(x, intercept, slope);\n}\n```\n:::\n:::\n",
    "supporting": [
      "day_1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}