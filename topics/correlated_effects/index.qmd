---
title: "Summarizing many univariate models"
description: |
  A secret weapon for when you're building hierarchical models.
execute:
  freeze: true
format:
  html:
    code-tools: true
---

We've already looked at univariate models. When we fit the same model to multiple different groups, we don't expect the same values for all the coefficients. Each thing we are studying will respond to the same variable in different ways.

Hierarchial models represent a way to *model* this variation, in ways that range from simple to complex.

Before we dive in with hierarchical structure, let's build a bridge between these two approaches.

This is useful to help us understand what a hierarchical model does.

However it is also useful from a strict model-building perspective -- so useful that [Andrew Gelman calls it a "Secret Weapon"](https://statmodeling.stat.columbia.edu/2005/03/07/the_secret_weap/)

```{r}
data(mite, package = "vegan")
data("mite.env", package = "vegan")

# combine data and environment
library(tidyverse)
mite_data_long <- bind_cols(mite.env, mite) |> 
  pivot_longer(Brachy:Trimalc2, names_to = "spp", values_to = "abd")
```

To keep things simple and univariate, let's consider only water:

First, a quick word about centering and scaling a predictor variable:

1.  I center the predictor by subtracting the mean. This changes the *intercept* of my linear predictor. it becomes the mean log-odds of occurrance when the water content is average
2.  I divide water content by 100. The dataset has units of **grams per Litre** of water (see `?vegan::mite.env` for more details). This is fine, but I don't think mites are able to sense differences as precise as a millimeter of water either way. by dividing by 10 I transform this into centilitres, which is more informative.

```{r}
mite_data_long_transformed <- mite_data_long |> 
  mutate(presabs = as.numeric(abd>0),
         # center predictors
         water = (WatrCont - mean(WatrCont)) / 100
         )

mite_data_long_transformed |> 
  ggplot(aes(x = water, y = presabs)) + 
  geom_point() + 
  stat_smooth(method = "glm", method.args = list(family = "binomial")) + 
  facet_wrap(~spp)
```

some things to notice about this figure:

-   the x-axis scale has been transformed from "grams per litre" to "centilitres away from average
-   there is a ton of variation in how different species respond to water!

```{r}
mite_many_glms <- mite_data_long_transformed |> 
  nest_by(spp) |> 
  mutate(logistic_regressions = list(
    glm(presabs ~ water,
        family = "binomial",
        data = data))) |> 
  mutate(coefs = list(broom::tidy(logistic_regressions)))
```

:::{.callout-note}
## Split-Apply-Combine

To explore this kind of thinking, we are going to use an approach sometimes called ["split-apply-combine"](https://vita.had.co.nz/papers/plyr.pdf)

There are many possible ways to do this in practice. We are using a technique here from the tidyverse, which you can [read more about](https://dplyr.tidyverse.org/articles/rowwise.html).
:::

```{r}
mite_many_glm_coefs <- mite_many_glms |> 
  select(-data, -logistic_regressions) |> 
  unnest(coefs)

mite_many_glm_coefs |> 
  ggplot(aes(x = estimate, y = spp,
             xmin = estimate - std.error,
             xmax = estimate + std.error)) + 
  geom_pointrange() + 
  facet_wrap(~term, scales = "free")
```

As you can see, some of these estimates are high, others low. We could also plot these as histograms to see this distribution.

```{r}
mite_many_glm_coefs |> 
  ggplot(aes(x = estimate)) + 
  geom_histogram(binwidth = .5) + 
  facet_wrap(~term, scales = "free")
```

Once again, the two parameters of this model represent:

-   *Intercept* The probability (in log-odds) of a species being present at the average water concentration. some species are common, others are rare.
-   *water* this is the change in probability (in log-odds) as water increases by one centilitre per litre of substrate.

## Say it in Stan

The above tidyverse approach is very appealing and intuitive, but we can also do the same procedure in Stan.

```{r}

library(cmdstanr)

all_species_unpooled <- cmdstan_model(
  stan_file = "topics/correlated_effects/all_species_unpooled.stan", 
  pedantic = TRUE)

mite_bin <- mite
mite_bin[mite_bin>0] <- 1

all_species_unpooled_posterior <- 
  all_species_unpooled$sample(
    data = list(
      n = nrow(mite_bin),
      S = ncol(mite_bin),
      x = with(mite.env, (WatrCont - mean(WatrCont))/100),
      y = as.matrix(mite_bin)
    ), 
    refresh = 0, parallel_chains = 4
    )
```

now let's try to plot this:

```{r}
#| warning: false
# start by looking at the names of variables
# get_variables(all_species_unpooled_posterior)

post_pred <- tidybayes::spread_rvars(all_species_unpooled_posterior, 
             intercept[spp_id], slope[spp_id]) |> 
  expand_grid(water = seq(from = -4, to = 4, length.out = 10)) |> 
  mutate(prob = posterior::rfun(plogis)(intercept + slope*water),
         spp = colnames(mite_bin)[spp_id]) |> 
  ggplot(aes(x = water, dist = prob)) + 
  tidybayes::stat_lineribbon() + 
  facet_wrap(~spp) + 
  scale_fill_brewer(palette = "Greens")

post_pred
```

```{r}
#| warning: false
post_pred + 
  geom_point(aes(x = water, y = presabs), 
             inherit.aes = FALSE, 
             data = mite_data_long_transformed,
             pch = 21, 
             fill = "orange")
```


Plot and compare to frequentist point estimates

```{r}
long_rvars <- tidybayes::gather_rvars(
  all_species_unpooled_posterior, 
             intercept[spp_id], slope[spp_id]) 


mite_many_glm_coefs |> 
  select(spp, term, estimate)

```


## Modelling variation in slopes

Clearly there is variation among species in the values of these parameters. Like all variation, we can develop a scientific model to describe it. The simplest model we'll consider is a simple univariate distribution.

```{r}
#| class.output: stan
suppressPackageStartupMessages(library(cmdstanr))

all_species_partpooled_diag <- cmdstan_model(
  stan_file = "topics/correlated_effects/all_species_partpooled_diag.stan", 
  pedantic = TRUE)

mite_bin <- mite
mite_bin[mite_bin>0] <- 1

mite_data_list <- list(
  Nsites = nrow(mite_bin),
  K = 2,
  S = ncol(mite_bin),
  x = cbind(1, with(mite.env, (WatrCont - mean(WatrCont))/100)),
  y = as.matrix(mite_bin))

all_species_partpooled_diag_posterior <- all_species_partpooled_diag$sample(
  data = mite_data_list,
  refresh = 0, parallel_chains = 4)
```


plot these, reproducing the figure from earlier:

```{r}

# get the unpooled numbers
unpooled_slopes <- all_species_unpooled_posterior |> 
  tidybayes::gather_rvars(slope[spp])

tidybayes::get_variables(all_species_partpooled_diag_posterior)

partpooled_slopes <- all_species_partpooled_diag_posterior |> 
  tidybayes::gather_rvars(beta[param, spp]) |> 
  filter(param == 2)

left_join(unpooled_slopes, partpooled_slopes, by = "spp") |> 
  ggplot(aes(x = mean(.value.x), y = mean(.value.y))) + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1)

```



<!-- Roadmap: -->

<!-- ### Simple model -->

<!-- * formula -->
<!-- * validation with bayesplot -->
<!-- * extraction and visualization with tidybayes -->

<!-- ### The secret weapon -->

<!-- * fit one model to each group -->
<!-- * plot their estimates -->
<!-- * extend the simple one-species model to use a vector of coefficients -->
<!-- * BONUS: tidy, nest by way -->

<!-- ### single species, no pooling regressions -->

<!-- * formula -->
<!-- * posterior predicitons with bayesplot -->
<!-- * extraction and visualization -->

<!-- ## single species, partial pooling but no correlation -->

<!-- * formula -->
<!-- * posterior predictions -->
<!-- * extract and visualize -->
<!-- * compare -->


<!-- * validation with bayesplot -->


<!-- * model comparison with LOO-ic, adding LogLik to the generated quantities -->




<!-- let's take a look at these values: -->

<!-- ```{r} -->
<!-- data("mite.xy", package = "vegan") -->
<!-- mite.xy -->
<!-- nrow(mite) -->
<!-- ``` -->

<!-- ## Ongoing discussions to have: -->

<!-- * how much "tooling" would we like to try and do?  for me, there is a difference between a "minimal" approach that is base R + cmdstanr, vs a bigger approach such as: -->

<!-- tidyverse -->
<!-- tidybayes (compose_data) -->
<!-- the posterior package (possibly interacting with tidybayes) -->
<!-- bayesplot -->

<!-- Then the bigger, more "meta" packages: -->
<!-- brms -->
<!-- rstanarm -->

<!-- correlated: -->


<!-- ```{r} -->
<!-- #| class.output: stan -->

<!-- # logistic_bern_glm_corr <- cmdstan_model( -->
<!-- #   stan_file = "topics/secret_weapon_correlated.stan",  -->
<!-- #   pedantic = TRUE) -->
<!-- #  -->
<!-- #  -->
<!-- # partpooling_samples <- logistic_bern_glm_corr$sample(data = mite_data_list) -->


<!-- ``` -->

