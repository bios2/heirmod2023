---
title: "Models with one level of hierarchy"
description: |
  Some of these things are somewhat like the others.
execute:
  freeze: true
comments:
  hypothesis: true
format:
  html:
    code-tools: true
editor_options: 
  chunk_output_type: console
---


:::{.callout-tip}
## Bayesian workflow

1. Visualize your data
2. Decide on your model structure
3. Simulate from the model to understand it
4. Fit the model to the data
5. Plot model predictions to evaluate the fit / draw conclusions
:::

Today's goal is to look at a couple of different model structures that we saw yesterday. 

```{r}
library(tidyverse)
library(cmdstanr)
library(tidybayes)
library(palmerpenguins)
```


## Gaussian random intercepts: Penguin body mass

**Are populations of penguins on different islands different in their body mass?**

The Palmer penguins are found on three different islands. Let's look at the distribution of body mass of each species on each island.

### Plot the data

```{r gauss-inter-setup}
penguin_mass_island <- penguins |> 
  select(species, island, body_mass_g) |> 
  drop_na(body_mass_g) |> 
  unite(sp_island, species, island) |> 
  ## center mass and change the units
  mutate(mass_kg = (body_mass_g)/1000)
```


```{r gauss-inter-plot}
penguin_mass_island |> 
  ggplot(aes(y = sp_island,
             x = mass_kg,
             colour = sp_island)) + 
  geom_jitter(alpha = 0.8, height = 0.1, width = 0) + 
  scale_color_brewer(palette = "Dark2")
```

Are the sample sizes equal among the species-island combinations?

```{r}
penguin_mass_island |> 
  count(sp_island) |> 
  knitr::kable()
```

### Decide on a model structure

We'll begin by fitting a model that assumes that body size for each of these five groups is completely independent:

$$
\begin{align}
\text{Body mass}_i &\sim \text{Normal}(\mu_i, \sigma_{\text{obs}}) \\
\mu_i &= \bar\beta + \beta_{\text{group}[i]} \\
\bar\beta &\sim \text{Normal}(5, 2) \\
\beta_{\text{group}} &\sim \text{Normal}(0, 1) \\
\sigma_{\text{obs}} &\sim \text{Exponential}(.5)
\end{align}
$$

### Simulate to understand this model {#sec-fixed-simulation}

Here's a little trick to get group indexes (numbers) from a character vector:

```{r}
group_names <- unique(penguin_mass_island$sp_island)
group_numbers <- seq_along(group_names)
names(group_numbers) <- group_names

group_numbers
```

```{r}
penguin_groupid <- penguin_mass_island |> 
  mutate(group_id = group_numbers[sp_island])

penguin_groupid
```

As you can see, we're set up now with the names and the indexes we need. 

Now we can simulate data and plot it:

```{r}
ngroup <- length(group_numbers)
overall_mean <- rnorm(1, mean = 5, sd = 2)
group_diffs <- rnorm(n = ngroup, mean = 0, sd = 1)
sigma_obs <- rexp(1, .5)

penguin_pred_obs <- penguin_groupid |> 
  mutate(fake_mass_avg = overall_mean + group_diffs[group_id],
         fake_mass_obs = rnorm(length(fake_mass_avg), 
                               mean = fake_mass_avg, 
                               sd = sigma_obs))

penguin_pred_obs |> 
  ggplot(aes(y = sp_island,
             x = fake_mass_obs,
             colour = sp_island)) + 
  geom_jitter(alpha = 0.8, height = 0.1, width = 0) + 
  scale_color_brewer(palette = "Dark2")

```

:::{.callout-tip}
### EXERCISE
Run the above code a few times! if you want, try different prior values.
:::

### Write it in Stan

```{r}
#| class-output: stan
fixed_groups <- cmdstan_model(stan_file = "topics/03_one_random_effect/fixed_groups.stan")

fixed_groups
```

### Fit the model

```{r}
peng_group_list <- with(penguin_groupid, 
         list(
           N = length(mass_kg),
           y = mass_kg,
           Ngroup = max(group_id),
           group_id = group_id
         ))

fixed_groups_samples <- fixed_groups$sample(
  data = peng_group_list,
  refresh = 0,
  parallel_chains = 4
)
```

### Plot predictions to evaluate results


Let's begin by plotting the averages for each group.

```{r}
fixed_groups_samples |> 
  gather_rvars(group_averages[group_id]) |> 
  mutate(sp_island = names(group_numbers)[group_id]) |> 
  ggplot(aes(y = sp_island, dist = .value)) + 
  stat_pointinterval() + 
  geom_jitter(data = penguin_mass_island,
              aes(y = sp_island,
                  x = mass_kg,
                  colour = sp_island), 
              pch = 21, inherit.aes = FALSE,
              alpha = 0.8, height = 0.1, width = 0) + 
  scale_colour_brewer(palette = "Dark2")
```


Some things to notice about the code above: 

* I'm using my named vector `group_numbers` to re-create the column `sp_island`. This is my technique for making sure I always use the correct label, but you can do this any way you want.
* We use `tidybayes::stat_pointinterval()` to summarize the posterior distribution.
* we're adding points from the original data (`penguin_mass_island`) with `geom_jitter()`. We're adding noise vertically to make the visualization better, but not adding any horizontal noise.

:::{.callout-tip}
### EXERCISE: plot posterior predictions of _observations_

Repeat the exercise above using the value of `one_obs_per_group`. 
Why are the results different? What additional error is included in these predictions?

:::

:::{.callout-note collapse="true"}
### SOLUTION

```{r}
fixed_groups_samples |> 
  tidybayes::gather_rvars(one_obs_per_group[group_id]) |> 
  mutate(sp_island = group_names[group_id]) |> 
  ggplot(aes(y = sp_island,
             dist = .value,
             colour = sp_island)) + 
  stat_pointinterval(colour = "black") + 
  geom_jitter(
    aes(y = sp_island,
        x = mass_kg,
        colour = sp_island), 
    inherit.aes = FALSE,
    alpha = .2, data = penguin_groupid, height = .2, width = 0) + 
  scale_colour_brewer(palette = "Dark2")

```

:::

### Make it hierarchical

#### Math


:::{.column-screen}

::::{.columns}

::: {.column width="2.5%"}
:::

::: {.column width="45%"}
$$
\begin{align}
\text{Body mass}_i &\sim \text{Normal}(\mu_i, \sigma_{\text{obs}}) \\
\mu_i &= \bar\beta + \beta_{\text{group}[i]} \\
\bar\beta &\sim \text{Normal}(5, 2) \\
\beta_{\text{group}} &\sim \text{Normal}(0, 1) \\
\sigma_{\text{obs}} &\sim \text{Exponential}(.5)
\end{align}
$$
:::

::: {.column width="5%"}

:::

::: {.column width="45%"}
$$
\begin{align}
\text{Body mass}_i &\sim \text{Normal}(\mu_i, \sigma_{\text{obs}}) \\
\mu_i &= \bar\beta + \beta_{\text{group}[i]} \\
\bar\beta &\sim \text{Normal}(5, 2) \\
\beta_{\text{group}} &\sim \text{Normal}(0, \sigma_{\text{sp}}) \\
\sigma_{\text{obs}} &\sim \text{Exponential}(.5) \\
\sigma_{\text{sp}} &\sim \text{Exponential}(1)
\end{align}
$$

:::

::: {.column width="2.5%"}

:::

::::

:::

#### Simulation of a hierarchical model

:::{.callout-tip}
### EXERCISE 
Simulate from the model above. Base your approach on the [code for simulation the non-hierarchical version](#sec-fixed-simulation). 
Remember to simulate one additional number: the standard deviation of group differences
:::

:::{.callout-note collapse="true"}
### SOLUTION
```{r}
ngroup <- length(group_numbers)
overall_mean <- rnorm(1, mean = 5, sd = 2)
sigma_group <- rexp(1, .1)
group_diffs <- rnorm(n = ngroup, mean = 0, sd = sigma_group)
sigma_obs <- rexp(1, .5)

penguin_pred_obs <- penguin_groupid |> 
  mutate(fake_mass_avg = overall_mean + group_diffs[group_id],
         fake_mass_obs = rnorm(length(fake_mass_avg), 
                               mean = fake_mass_avg, 
                               sd = sigma_obs))

penguin_pred_obs |> 
  ggplot(aes(y = sp_island,
             x = fake_mass_obs,
             colour = sp_island)) + 
  geom_jitter(alpha = 0.8, height = 0.1, width = 0) + 
  scale_color_brewer(palette = "Dark2")

```
:::

#### Stan


Below I'm comparing the two Stan programs side-by-side. Compare them to the models above! 

```{r}
hierarchical_groups <- cmdstan_model(stan_file = "topics/03_one_random_effect/hierarchical_groups.stan")
```

:::{.column-screen}

::::{.columns}

::: {.column width="2.5%"}
:::

::: {.column width="45%"}
```{r}
#| class-output: stan
fixed_groups
```

:::

::: {.column width="5%"}

:::

::: {.column width="45%"}

```{r}
#| class-output: stan
hierarchical_groups
```


:::

::: {.column width="2.5%"}

:::

::::

:::



```{r}
hierarchical_groups_samples <- hierarchical_groups$sample(
  data = peng_group_list, refresh = 0, parallel_chains = 4)
```

```{r}
hierarchical_groups_samples
```

```{r}
hierarchical_groups_samples |> 
  tidybayes::gather_rvars(b_group[group_id],
                          new_b_group) |> 
  mutate(sp_island = group_names[group_id],
         sp_island = if_else(is.na(sp_island),
                             true = "New Group",
                             false = sp_island)) |> 
  ggplot(aes(y = sp_island,
             dist = .value,
             colour = sp_island)) + 
  stat_pointinterval()
```


```{r}
hierarchical_groups_samples |> 
  tidybayes::gather_rvars(one_obs_per_group[group_id],
                          one_obs_new_group) |> 
  mutate(sp_island = group_names[group_id],
         sp_island = if_else(is.na(sp_island),
                             true = "New Group",
                             false = sp_island)) |> 
  ggplot(aes(y = sp_island,
             dist = .value,
             colour = sp_island)) + 
  stat_pointinterval() + 
  geom_point(aes(y = sp_island,
             x = mass_kg,
             colour = sp_island), 
             inherit.aes = FALSE,
             alpha = .2, data = penguin_groupid)
```


## Exercises

1. Try leaving out a group and refitting the hierarchical model. Are the predictions for the missing group accurate?
1. There are other categorical predictors in the dataset. Try including `year` as a part of the group-creating factor (i.e. in the call to `unite()` above). What changes?
1. The posterior for both models includes a predicted `fake_obs` for EVERY observation. This opens the possibility of using `bayesplot` to make predictions. Look back at the code from Day 1 and create a posterior predictive check for both models. (e.g. using `ppc_dens_overlay`)
1. We could perhaps have used `sex` as a grouping factor, but `sex` has missing values in it! Why is this a problem for this kind of model? What would it take to address that? (Discussion only; missing values are unfortunately outside the class scope!)

## Observation-level random effects: Mite abundance

### What is the question? 

Let's write a model to answer the question:  

**How does the total abundance of the mite community change as water content increases?**  

### Express this in Math

Here's a partially complete model for species richness over time

$$
\begin{align}
\text{S}_i &\sim \text{Poisson}(e^a) \\
a &= \bar\beta + \beta_{\text{water}} \cdot \text{water}_i \\
\bar\beta &\sim \text{Normal}(?, ?) \\
\beta_{\text{water}} &\sim \text{Normal}(?, ?) \\
\end{align}
$$

:::{.callout-tip}
### EXERCISE 
Simulate from this model, and look at your simulations to decide on a reasonable prior for the data.
:::

:::{.callout-note collapse="true"}
### SOLUTION
```{r}
n <- 30
water <- seq(from = -5, to = 5, length.out = n)

b0 <- rnorm(1, mean = log(17), sd = .3)
b1 <- rnorm(1, mean = 0, sd = .2)

S <- rpois(n, lambda = exp(b0 + b1*water))
plot(water, S)
```
:::

### Data preparation & visualization

First we need to load and prepare the data:

```{r}
data(mite, package = "vegan")
data("mite.env", package = "vegan")

# combine data and environment

mite_data_long <- mite |> 
  tibble::rownames_to_column(var = "site_id") |> 
  bind_cols(mite.env) |> 
  pivot_longer(Brachy:Trimalc2,
               names_to = "spp", values_to = "abd")
```


First let's transform the mite dataset into a dataframe of species richness per site. 
We'll also standardize the water content while we're at it:

```{r}
mite_species_richness <- mite_data_long |> 
  group_by(site_id, WatrCont) |> 
  summarize(S = sum(abd)) |>
  ungroup() |> 
  mutate(water_c = (WatrCont - mean(WatrCont))/100)

head(mite_species_richness)
```

We get a nice histogram of species richness, and a clear negative relationship with water volume:

```{r}
#| layout-ncol: 2
mite_species_richness |> 
  ggplot(aes(x = S)) + 
  geom_histogram()

mite_species_richness |> 
  ggplot(aes(x = water_c, y = S)) + 
  geom_point()
```

### Write the model in Stan and estimate it

```{r}
poisson_regression <- cmdstan_model(stan_file = "topics/03_one_random_effect/poisson_regression.stan")
```

```{r}

water_for_pred <- seq(from = -3, to = 4.5, length.out = 15)

abd_data_list <- list(N = length(mite_species_richness$S),
              water = mite_species_richness$water_c,
              y = mite_species_richness$S,
              Npred = 15,
              water_pred = water_for_pred)

poisson_regression_sample <- poisson_regression$sample(
  data = abd_data_list,
  refresh = 0)
```

### Plot the model to see if it fits well

```{r}
#| layout-ncol: 2
poisson_regression_sample |> 
  tidybayes::gather_rvars(line_obs[i]) |> 
  mutate(water = water_for_pred) |> 
  ggplot(aes(x = water, dist = .value)) + 
  stat_lineribbon() + 
  geom_point(aes(x = water_c, y = S), data = mite_species_richness, inherit.aes = FALSE)

fake_obs_S <- poisson_regression_sample$draws(variables = "fake_obs")
fake_obs_S_matrix <- posterior::as_draws_matrix(fake_obs_S)

bayesplot::ppc_dens_overlay(y = mite_species_richness$S,
                            yrep = head(fake_obs_S_matrix, 50))
```


:::{.callout-tip
### EXERCISE
1) Add a random effect for _every individual observation_ in the model. Begin by writing the mathematical notation for this new model! 

2) fit the model and re-create the two figures above. What do you notice? 

* Which model is more trustworthy?
* look at the slope in the new model. Is it different?
:::

:::{.callout-note collapse="true"}
### SOLUTION


#### Mathematical notation

$$
\begin{align}
\text{S}_i &\sim \text{Poisson}(e^a) \\
a &= \bar\beta + \beta_{\text{water}} \cdot \text{water}_i + \text{site}_i\\
\bar\beta &\sim \text{Normal}(?, ?) \\
\beta_{\text{water}} &\sim \text{Normal}(?, ?) \\
\text{site} &\sim \text{Normal}(?, \sigma) \\
\sigma &\sim \text{Exponential}(?)
\end{align}
$$

#### Stan code 


```{r}
poisson_regression_overdisp <- cmdstan_model(stan_file = "topics/03_one_random_effect/poisson_regression_overdisp.stan")

poisson_regression_overdisp_sample <- poisson_regression_overdisp$sample(
  data = abd_data_list, refresh = 0)
```


```{r}
#| layout-ncol: 2
#| 
fake_obs_S <- poisson_regression_overdisp_sample$draws(variables = "fake_obs")
fake_obs_S_matrix <- posterior::as_draws_matrix(fake_obs_S)

bayesplot::ppc_dens_overlay(y = mite_species_richness$S,
                            yrep = head(fake_obs_S_matrix, 50))

poisson_regression_overdisp_sample |> 
  tidybayes::gather_rvars(line_obs[i]) |> 
  mutate(water = water_for_pred) |> 
  ggplot(aes(x = water, dist = .value)) + 
  stat_lineribbon() + 
  geom_point(aes(x = water_c, y = S), data = mite_species_richness, inherit.aes = FALSE)
```

:::



:::{.callout-note}
Another great way to model overdispersion is via the [Negative Binomial](https://en.wikipedia.org/wiki/Negative_binomial_distribution) distribution. Look at the Stan documentation for [neg_binomial_2_log](https://mc-stan.org/docs/functions-reference/neg-binom-2-log.html) and adapt your model to use it (don't forget to drop the random effect when you do!).
:::

:::{.callout-warning}
The code below is EXTRA material showing other examples you might be interested in! 
:::


## Bernoulli presence-absence data: Mite occurrance.

**Which mite species are found in which site?**

Let's begin by drawing a classic picture: a species by site matrix!

### Visualizing 

```{r}
#| fig-cap: A species x site matrix for the mite data. 

species_numbers <- with(mite_data_long,
                        setNames(seq_along(unique(spp)), unique(spp)))

mite_data_groupID <- mutate(mite_data_long,
                            group_id = species_numbers[spp])

 
mite_list <- with(mite_data_groupID,
                  list(
                    N = length(abd),
                    y = abd,
                    Ngroup = dplyr::n_distinct(spp),
                    group_id = group_id
                  ))


mite_long_pa <- mite_data_groupID |> 
  mutate(pa = as.numeric(abd > 0))

mite_long_pa |> 
  mutate(
    spp = forcats::fct_reorder(spp, pa),
    site_id = forcats::fct_reorder(site_id, pa),
    pa = as.character(pa)) |>
  ggplot(aes(x = site_id, y = spp, fill = pa)) + 
  geom_tile() + 
  scale_fill_manual(values = c("1" = "black", "0" = "white")) + 
  coord_fixed()
```

### Mathematics

$$
\begin{align}
\text{Pr(y = 1)} &\sim \text{Bernoulli}(p) \\
\text{logit}(p) &= \bar\beta + \beta_{\text{site}[i]} + \beta_{\text{species}[i]} \\
\bar\beta &\sim N(0,.5) \\
\beta_{\text{site}} &\sim N(0, .2) \\
\beta_{\text{species}} &\sim N(0, \sigma_{\text{spp}}) \\
\sigma_{\text{spp}} &\sim \text{Exponential}(2)
\end{align}
$$


```{r eval=FALSE, include = FALSE}
brms::brm(pa ~ 1 + site_id + (1 | spp), family = "bernoulli", data= mite_long_pa)
```

```{r}
#| class-output: stan
bernoulli_spp_site <- cmdstan_model(stan_file = "topics/03_one_random_effect/bernoulli_spp_site.stan")

bernoulli_spp_site
```

```{r}
bernoulli_mite_spp <- bernoulli_spp_site$sample(data = list(
  N = nrow(mite_long_pa),
  y = mite_long_pa$pa,
  Nsite = max(as.numeric(mite_long_pa$site_id)),
  site_id = as.numeric(mite_long_pa$site_id),
  Nspp = max(mite_long_pa$group_id),
  spp_id = mite_long_pa$group_id
),parallel_chains = 2, refresh = 0, chains = 2)
```

```{r}
# tidybayes::get_variables(bernoulli_mite_spp)
```

This model can produce a probability that any species occurs in any plot:

```{r}
mite_occ_prob_logit <- bernoulli_mite_spp |> 
  tidybayes::gather_rvars(prob_occurence[spp_id, site_id])

## transform into probabilities
mite_occ_prob <- mite_occ_prob_logit |> 
  mutate(prob = posterior::rfun(plogis)(.value))

mite_occ_prob |> 
  mutate(med_prob = median(prob),
         spp_id  = forcats::fct_reorder(as.factor(spp_id), med_prob),
         site_id = forcats::fct_reorder(as.factor(site_id), med_prob)) |> 
  ggplot(aes(x = spp_id, y = site_id, fill = med_prob)) + 
  geom_tile()
```

### Exercises:

1. How could you assess this model fit to data? What kind of figure would be most interesting?
1. The probability of a species occurring across all sites is given by `b_avg + b_spp`. How does that compare to the fraction of sites at which any species was observed?
1. The expected species richness of each site is given by `b_avg + b_site`. How does that compare to the observed species richness?



## Poisson random intercepts: Mite abundance

**How does mite abundance vary among sites?**

```{r}
#| fig-cap: Abundance of each species at every site in the mite dataset. Points are species abundances, grouped on the row for that site.
mite_data_long |> 
  mutate(site_id = forcats::fct_reorder(site_id, abd)) |> 
  ggplot(aes(y = site_id, x = abd)) +
  geom_point() + 
  coord_cartesian(xlim = c(0,100)) + 
  stat_summary(fun = median, col = "red", geom = "point")
```

:::{.callout-tip}
### write the model in the same notation as the original

Let's model the counts of species abundances, using a random effect for each site. Write the model that corresponds to this!

:::


### Trying it with a Normal distribution:

It's actually possible to run the previous model on this one.
let's set up the data and try:
```{r}
species_numbers <- with(mite_data_long,
     setNames(seq_along(unique(spp)), unique(spp)))

mite_data_groupID <- mutate(mite_data_long,
                            group_id = species_numbers[spp])

mite_list <- with(mite_data_groupID,
                  list(
                    N = length(abd),
                    y = abd,
                    Ngroup = dplyr::n_distinct(spp),
                    group_id = group_id
                  ))

normal_samples <- hierarchical_groups$sample(data = mite_list, refresh = 0, parallel_chains = 4)
```

This is interesting, but it would probably be better to fit this model with something meant for counts! With this comes the need to include a log link function. Fortunately, Stan makes all this possible with just a few small changes:

### Exercise: translate it into Stan

Modify the program `hierarchical_groups.stan` to work for poisson data. Some things to keep in mind: 

* `data {}` block: remember that the Poisson distribution needs integers and set up the data inputs accordinly.
* `parameters {}` block: think about which parameters the poisson does NOT need. 
* `model {}` block: remember to remove any unneeded parameters from the likelihood (the model of the data), and their priors too.
* replace `normal` with `poisson_log`. Note that this evaluates its argument on the log scale. That is, it works like a typical GLM done in R. We can keep priors the same as in the last model, though we may decide to change their values.
* `generated quantities {}` block: replace `normal_rng()` with `poisson_log_rng()` -- _where necessary_ -- and delete unused parameters.
* again, remember that the Poisson needs to be making integers. For example, replace `vector[Ngroup]` with `array[Ngroup] int `

```{r include=FALSE, eval=FALSE}
phg <- cmdstan_model(stan_file = "topics/03_one_random_effect/poisson_hier_groups.stan")

phg_samples <- phg$sample(data = mite_list, refresh = 20, parallel_chains = 2, chains = 2)

phg_samples |> 
  gather_rvars(one_obs_per_group[i]) |> 
  mutate(spp = names(species_numbers)[i],
         spp = forcats::fct_reorder(spp, .value, median)) |> 
  ggplot(aes(y = spp, dist = .value)) + 
  stat_pointinterval() + 
  geom_point(aes(y = spp, x = m),
             data = mite_data_groupID |> 
               group_by(spp) |> 
               summarize(m = mean(abd)),
             inherit.aes = FALSE, col = "red")
```

### Exercises

* Try modifying the program again, this time adding a predictor: water content. What happens to `sigma_grp` in this example?



## Extra stuff

Let's use simulations to demonstrate that univariate normal distributions are special cases of multivariate normal distributions:

```{r}
mysigma <- 3
nsamp <- 1100

hist(rnorm(nsamp, 0, mysigma))

mySigma <- diag(mysigma, nrow = nsamp)

mv_numbers <- MASS::mvrnorm(1, mu = rep(0, nsamp), Sigma = mySigma)
hist(mv_numbers)
```

